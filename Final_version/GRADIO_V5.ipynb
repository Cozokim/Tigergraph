{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "secret token: ug9mkc24jtimcc9j0b2qo8dkjhjfdfh3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JulienRigot\\Projets\\zzEnvs\\Transport\\Lib\\site-packages\\pyTigerGraph\\pyTigerGraphBase.py:105: DeprecationWarning: The `apiToken` parameter is deprecated; use `getToken()` function instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#CLUSTER GORDIAS LIS \n",
    "import pyTigerGraph as tg\n",
    "import pandas as pd\n",
    "import gradio as gr\n",
    "hostName = \"https://d6e9eef375704c8893b47bdc6132b082.i.tgcloud.io\"\n",
    "graphName = \"VWG\"\n",
    "secret = \"8uan20otpbh626fl4s449aumie58o4h9\"\n",
    "userName = \"user_1\"\n",
    "password = \"A1z2e3r4*\"\n",
    "tigergraph_insights_map = \"https://tools.tgcloud.io/insights/app/qepJkoYLXfcWTB4d5ExgVT/page/4NjQNvfLhhTXHgQZBkyxtM/widgetShare/6wci2PjrXvzciTfmrH9pQY?domain=d6e9eef375704c8893b47bdc6132b082.i&orgName=lis-gordias&clusterid=507badf1-6ed3-4a79-9aaa-82489ed609ef&TigerGraphToken=e4120fbd-1fb5-4383-a727-33fb7032eb53\"\n",
    "graph = tg.TigerGraphConnection(host=hostName, graphname=graphName)\n",
    "\n",
    "authToken = graph.getToken(secret)\n",
    "authToken = authToken[0]\n",
    "print(f\"secret token: {authToken}\")\n",
    "conn = tg.TigerGraphConnection(host=hostName, graphname=graphName, username=userName, password=password, apiToken=authToken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "secret token 1: 395kqmln948q1cf8aspr7vnd479l216i\n"
     ]
    }
   ],
   "source": [
    "# # FREE CLUSTER EDGE\n",
    "hostName1 = \"https://506118e7a5824411b8cff3b579d8809b.i.tgcloud.io\"\n",
    "graphName1 = \"VWG1\"\n",
    "secret1 = \"4alh4gsrhiq5tlfb3tf5gro5srpa5e35\"\n",
    "userName1 = \"user_1\"\n",
    "password1 = \"A1z2e3r4*\"\n",
    "tigergraph_insights_map1 = \"https://tools.tgcloud.io/insights/app/gBQu5GpNcMMoNttUGH8t29/page/mwMTnWnUDwp1PgFEE5Vapi/widgetShare/veFZVtxZW1gpd4GXchssZ2?domain=506118e7a5824411b8cff3b579d8809b.i&orgName=jrlisdata-org-2024325&clusterid=95a180a6-6c60-4d83-94ff-5291bf665469&TigerGraphToken=2cf416dd-3e79-4428-a5c0-1a68168b608b\"\n",
    "graph1 = tg.TigerGraphConnection(host=hostName1, graphname=graphName1)\n",
    "\n",
    "authToken1 = graph1.getToken(secret1)\n",
    "authToken1 = authToken1[0]\n",
    "print(f\"secret token 1: {authToken1}\")\n",
    "conn1 = tg.TigerGraphConnection(host=hostName1, graphname=graphName1, username=userName1, password=password1, apiToken=authToken1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleted = conn1.upsertEdge(sourceVertexType=\"Nodes\",targetVertexType=\"Nodes\",\n",
    "#                         sourceVertexId=\"Las Palmas de Gran Canaria\",targetVertexId=\"Seville\",edgeType=\"distribute_to\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tab 0 (cargar datos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import threading\n",
    "atributes_nodes = {}\n",
    "atributes_edges = {}\n",
    "\n",
    "# Helper functions\n",
    "def path_taken(results):\n",
    "    # Extrae el conjunto de aristas desde el diccionario de resultados.\n",
    "    edges = results[2]['@@display_edge_set']\n",
    "    \n",
    "    # Inicializa una variable para almacenar el nodo inicial.\n",
    "    node_initial = None\n",
    "    \n",
    "    # Crea un conjunto de identificadores de nodos a los que se dirige cada arista.\n",
    "    edge_to_ids = {edge['to_id'] for edge in edges}\n",
    "    \n",
    "    # Busca el nodo inicial (el nodo que no es el destino de ningún arista).\n",
    "    for edge in edges:\n",
    "        if edge['from_id'] not in edge_to_ids:\n",
    "            node_initial = edge['from_id']\n",
    "            break\n",
    "    \n",
    "    # Si no se encuentra un nodo inicial, lanza una excepción.\n",
    "    if node_initial is None:\n",
    "        raise ValueError(\"initial node cannot be determined.\")\n",
    "    \n",
    "    # Inicializa el nodo actual como el nodo inicial y crea una lista para el camino.\n",
    "    current_node = node_initial\n",
    "    path = [current_node]\n",
    "    \n",
    "    # Recorre los bordes para construir el camino desde el nodo inicial.\n",
    "    while True:\n",
    "        next_node = None\n",
    "        \n",
    "        # Busca el siguiente nodo en el camino basado en el nodo actual.\n",
    "        for edge in edges:\n",
    "            if edge['from_id'] == current_node:\n",
    "                next_node = edge['to_id']\n",
    "                break\n",
    "        \n",
    "        # Si no se encuentra el siguiente nodo, termina el bucle.\n",
    "        if next_node is None:\n",
    "            break\n",
    "        \n",
    "        # Añade el siguiente nodo al camino y actualiza el nodo actual.\n",
    "        path.append(next_node)\n",
    "        current_node = next_node\n",
    "    \n",
    "    # Crea un diccionario de nodos mapeando cada nodo a sí mismo.\n",
    "    nodes = {node_name: node_name for node_name in path}\n",
    "    \n",
    "    # Crea una lista ordenada de nodos basada en el camino encontrado.\n",
    "    ordered_nodes = [nodes[node_name] for node_name in path]\n",
    "    \n",
    "    # Devuelve la lista de nodos ordenados que representa el camino tomado.\n",
    "    return ordered_nodes\n",
    "\n",
    "\n",
    "def add_or_update_final_nodes_batch(nodes_batch_full, nodes_batch, charge):\n",
    "    # Crea una lista de ciudades existentes a partir de los nodos en 'nodes_batch_full'.\n",
    "    existing_cities = [city for city, _ in nodes_batch_full]\n",
    "    \n",
    "    # Itera sobre cada nodo en el 'nodes_batch' para actualizar o agregar nodos en 'nodes_batch_full'.\n",
    "    for node, _ in nodes_batch:\n",
    "        if node in existing_cities:\n",
    "            # Si el nodo ya existe en 'nodes_batch_full', busca el índice del nodo para actualizar el stock.\n",
    "            for i, (city, stock) in enumerate(nodes_batch_full):\n",
    "                if city == node:\n",
    "                    # Si es el primer nodo, decrementa el stock por 'charge'.\n",
    "                    # De lo contrario, incrementa el stock por 'charge'.\n",
    "                    if i == 0:\n",
    "                        nodes_batch_full[i] = (city, {\"Stock\": nodes_batch_full[i][1][\"Stock\"] - charge})\n",
    "                    else:\n",
    "                        nodes_batch_full[i] = (city, {\"Stock\": nodes_batch_full[i][1][\"Stock\"] + charge})\n",
    "            continue\n",
    "        else:\n",
    "            # Si el nodo no está en 'nodes_batch_full', agrega nuevas entradas para los nodos de 'nodes_batch'.\n",
    "            nodes_batch_full.extend([\n",
    "                (nodes_batch[0][0], {\"Stock\": nodes_batch[0][1][\"Stock\"]}),\n",
    "                (nodes_batch[1][0], {\"Stock\": nodes_batch[1][1][\"Stock\"]})\n",
    "            ])\n",
    "            # Retorna 'nodes_batch_full' después de agregar las nuevas entradas.\n",
    "            return nodes_batch_full\n",
    "    \n",
    "    # Retorna 'nodes_batch_full' después de actualizar o agregar los nodos.\n",
    "    return nodes_batch_full\n",
    "\n",
    "def add_or_update_final_edges_batch(edges_batch_full, edges_batch, charge):\n",
    "    # Crea una lista de bordes existentes a partir de 'edges_batch_full', considerando ambos sentidos.\n",
    "    existing_edges = [(edge[0], edge[1]) for edge in edges_batch_full]\n",
    "    \n",
    "    # Itera sobre cada borde en 'edges_batch' para actualizar o agregar bordes en 'edges_batch_full'.\n",
    "    for edge in edges_batch:\n",
    "        # Verifica si el borde ya existe en 'edges_batch_full' considerando ambos sentidos.\n",
    "        if (edge[0], edge[1]) in existing_edges or (edge[1], edge[0]) in existing_edges:\n",
    "            # Si el borde ya existe, busca el índice del borde para actualizar el movimiento diario.\n",
    "            for i, (origin, destination, movement) in enumerate(edges_batch_full):\n",
    "                # Compara ambos sentidos del borde para encontrar el índice correcto.\n",
    "                if (origin, destination) == (edge[0], edge[1]) or (origin, destination) == (edge[1], edge[0]):\n",
    "                    # Actualiza el movimiento diario del borde sumando 'charge'.\n",
    "                    edges_batch_full[i] = (origin, destination, {\"Daily_movement\": edges_batch_full[i][2][\"Daily_movement\"] + charge})\n",
    "            continue\n",
    "        else:\n",
    "            # Si el borde no existe, agrega una nueva entrada en 'edges_batch_full'.\n",
    "            edges_batch_full.append((edge[0], edge[1], {\"Daily_movement\": edge[2][\"Daily_movement\"]}))\n",
    "    \n",
    "    # Retorna 'edges_batch_full' después de actualizar o agregar los bordes.\n",
    "    return edges_batch_full\n",
    "\n",
    "\n",
    "def actualize_graph_carga(conn=conn):\n",
    "    # Obtiene la lista de nodos y aristas desde la conexión proporcionada.\n",
    "    nodes = conn.getVertices(\"Nodes\")\n",
    "    aristas = conn.getEdgesByType(edgeType=\"distribute_to\")\n",
    "\n",
    "    # Inicializa listas para almacenar nodos y aristas con datos escalados.\n",
    "    nodes_batch_scale = []\n",
    "    aristas_batch_scale = []\n",
    "    \n",
    "    # Inicializa una variable para registrar los estados de nodos y aristas.\n",
    "    logs_state_nodes_and_arristas = \"\"\n",
    "\n",
    "    # Contadores para los diferentes niveles de carga de nodos y aristas.\n",
    "    node_counts = {\"Sobrecargado\": 0, \"Subcargado\": 0, \"Optimal\": 0}\n",
    "    arista_counts = {\"Sobrecargado\": 0, \"Subcargado\": 0, \"Optimal\": 0}\n",
    "\n",
    "    # Itera sobre cada nodo para determinar su nivel de carga.\n",
    "    for node in nodes:\n",
    "        node_capacidad = node[\"attributes\"][\"Capacity\"]\n",
    "        node_stock = node[\"attributes\"][\"Stock\"]\n",
    "        \n",
    "        # Determina el nivel de carga del nodo basado en su capacidad y stock.\n",
    "        if node_capacidad == 0:\n",
    "            nivel_stock = \"No definido\"\n",
    "        else:\n",
    "            if (node_stock / node_capacidad) > 1:\n",
    "                nivel_stock = \"Sobrecargado\"\n",
    "                node_counts[\"Sobrecargado\"] += 1\n",
    "                logs_state_nodes_and_arristas += f\"⚠️ {node['v_id']} es {nivel_stock} \\n\"\n",
    "            elif 0.7 < (node_stock / node_capacidad) <= 1:\n",
    "                nivel_stock = \"Optimal\"\n",
    "                node_counts[\"Optimal\"] += 1\n",
    "            else:\n",
    "                nivel_stock = \"Subcargado\"\n",
    "                logs_state_nodes_and_arristas += f\"⚠️ {node['v_id']} es {nivel_stock} \\n\"\n",
    "                node_counts[\"Subcargado\"] += 1\n",
    "\n",
    "        # Añade el nodo con su nivel de carga a la lista de nodos a escalar.\n",
    "        nodes_batch_scale.append((node[\"v_id\"], {\"Carga\": nivel_stock}))\n",
    "\n",
    "    # Itera sobre cada arista para determinar su nivel de carga.\n",
    "    for arista in aristas:\n",
    "        capacity_edge = arista[\"attributes\"][\"Capacity\"]\n",
    "        daily_movement = arista[\"attributes\"][\"Daily_movement\"]\n",
    "        \n",
    "        # Determina el nivel de carga de la arista basado en su capacidad y movimiento diario.\n",
    "        if capacity_edge == 0:\n",
    "            nivel_arista = \"No definido\"\n",
    "        else:\n",
    "            if (daily_movement / capacity_edge) > 1:\n",
    "                nivel_arista = \"Sobrecargado\"\n",
    "                arista_counts[\"Sobrecargado\"] += 1\n",
    "                logs_state_nodes_and_arristas += f\"⚠️ la arista {arista['from_id']} hasta {arista['to_id']} es {nivel_arista} \\n\"\n",
    "            elif 0.7 < (daily_movement / capacity_edge) <= 1:\n",
    "                nivel_arista = \"Optimal\"\n",
    "                arista_counts[\"Optimal\"] += 1\n",
    "            else:\n",
    "                nivel_arista = \"Subcargado\"\n",
    "                logs_state_nodes_and_arristas += f\"⚠️ la arista {arista['from_id']} hasta {arista['to_id']} es {nivel_arista} \\n\"\n",
    "                arista_counts[\"Subcargado\"] += 1\n",
    "\n",
    "        # Añade la arista con su nivel de carga a la lista de aristas a escalar.\n",
    "        aristas_batch_scale.append((arista[\"from_id\"], arista[\"to_id\"], {\"Carga\": nivel_arista}))\n",
    "\n",
    "    # Actualiza los nodos en la base de datos con los datos escalados.\n",
    "    conn.upsertVertices(\"Nodes\", nodes_batch_scale)\n",
    "    \n",
    "    # Actualiza las aristas en la base de datos con los datos escalados.\n",
    "    conn.upsertEdges(sourceVertexType=\"Nodes\", targetVertexType=\"Nodes\", edgeType=\"distribute_to\", edges=aristas_batch_scale)\n",
    "\n",
    "    # Si no se registraron cambios, indica que todos los nodos y aristas están en un estado óptimo.\n",
    "    if logs_state_nodes_and_arristas == \"\":\n",
    "        logs_state_nodes_and_arristas = \"Todos los nodos y aristas están en un estado óptimo.\"\n",
    "\n",
    "    # Crea un diccionario con los registros de estado y los conteos de nodos y aristas.\n",
    "    results = {\n",
    "        \"logs\": logs_state_nodes_and_arristas,\n",
    "        \"node_counts\": node_counts,\n",
    "        \"arista_counts\": arista_counts\n",
    "    }\n",
    "\n",
    "    # Retorna el diccionario con los resultados.\n",
    "    return results\n",
    "\n",
    "\n",
    "# Main transfer function\n",
    "\n",
    "def transfert_nodes_and_edges(node_initial, node_final, charge, weight_attribute=\"Capacity\", nodetype=\"Nodes\", edgetype=\"distribute_to\"):\n",
    "\n",
    "    # Lanza la función A* para encontrar el camino óptimo entre node_initial y node_final\n",
    "    results_astar = conn.runInstalledQuery(\"tg_astar\", params={\n",
    "        \"source_vertex\": node_final, \"source_vertex.type\": nodetype,\n",
    "        \"target_vertex\": node_initial, \"target_vertex.type\": nodetype,\n",
    "        \"e_type_set\": edgetype, \"weight_type\": \"FLOAT\",\n",
    "        \"latitude\": \"latitude\", \"longitude\": \"longitude\",\n",
    "        \"weight_attribute\": weight_attribute,\n",
    "        \"print_stats\": \"True\"\n",
    "    })\n",
    "    \n",
    "    # Obtiene el orden de los nodos en el camino encontrado\n",
    "    order_taken = path_taken(results_astar)\n",
    "    \n",
    "    # Obtiene el conjunto de aristas involucradas en el camino\n",
    "    edge_set = results_astar[2]['@@display_edge_set']\n",
    "    \n",
    "    # Reorganiza las aristas de acuerdo al orden de los nodos en el camino\n",
    "    reordered_edges_set = []\n",
    "    for location in order_taken:\n",
    "        for edge in edge_set:\n",
    "            if edge['from_id'] == location:\n",
    "                reordered_edges_set.append(edge)\n",
    "\n",
    "    # Obtiene el conjunto de nodos involucrados en el camino\n",
    "    node_set = results_astar[2]['tmp']\n",
    "    \n",
    "    # Reorganiza los nodos de acuerdo al orden en el camino\n",
    "    reordered_nodes_set = []\n",
    "    for location in order_taken:\n",
    "        for item in node_set:\n",
    "            if item['v_id'] == location:\n",
    "                reordered_nodes_set.append(item)\n",
    "\n",
    "    try:\n",
    "        # Recupera los atributos de los nodos inicial y final\n",
    "        node_i_stock = reordered_nodes_set[0][\"attributes\"][\"Stock\"]\n",
    "        node_f_stock = reordered_nodes_set[-1][\"attributes\"][\"Stock\"]\n",
    "        node_i_unload_capacity = reordered_nodes_set[0][\"attributes\"][\"UnloadCapacity\"]\n",
    "        node_f_load_capacity = reordered_nodes_set[-1][\"attributes\"][\"LoadCapacity\"]\n",
    "\n",
    "        # Verifica si hay suficiente inventario en el nodo inicial\n",
    "        if charge > node_i_stock:\n",
    "            error_message = f\"{node_initial} hasta {node_final}: No hay suficiente inventario ({charge} > {node_i_stock})\\n\"\n",
    "            log_list += error_message\n",
    "\n",
    "        # Verifica si hay suficiente capacidad de carga en el nodo final\n",
    "        if charge > node_f_load_capacity:\n",
    "            error_message = f\"{node_initial} hasta {node_final}: No hay suficiente capacidad de carga en el almacén de recepción (charge: {charge} > LoadCapacity: {node_f_load_capacity})\\n\"\n",
    "            log_list += error_message\n",
    "\n",
    "        # Verifica si hay suficiente capacidad de descarga en el nodo inicial\n",
    "        if charge > node_i_unload_capacity:\n",
    "            error_message = f\"{node_initial} hasta {node_final}: No hay suficiente capacidad de descarga desde el almacén de salida (charge: {charge} > UnloadCapacity: {node_i_unload_capacity})\\n\"\n",
    "            log_list += error_message\n",
    "\n",
    "        # Recupera la capacidad de la arista y el movimiento diario actual\n",
    "        capacity_edge = reordered_edges_set[0][\"attributes\"][\"Capacity\"]\n",
    "        daily_movement = reordered_edges_set[0][\"attributes\"][\"Daily_movement\"]\n",
    "\n",
    "        # Verifica si la arista puede soportar el movimiento adicional de carga\n",
    "        if daily_movement + charge > capacity_edge:\n",
    "            error_message = f\"Enviar {charge} palets desde {node_initial} hasta {node_final}: Capacidad de la arista insuficiente ({daily_movement + charge} > {capacity_edge})\\n\"\n",
    "            log_list += error_message\n",
    "\n",
    "        # Actualiza los inventarios de los nodos inicial y final\n",
    "        nodes_batch = [\n",
    "            (node_initial, {\"Stock\": node_i_stock - charge}),\n",
    "            (node_final, {\"Stock\": node_f_stock + charge})\n",
    "        ]\n",
    "\n",
    "        # Actualiza el movimiento diario en las aristas recorridas y acumula el costo\n",
    "        edges_batch = []\n",
    "        for element in reordered_edges_set:\n",
    "            element['attributes']['Daily_movement'] += charge\n",
    "            edges_batch.append((element[\"from_id\"], element[\"to_id\"], {\"Daily_movement\": element[\"attributes\"][\"Daily_movement\"]}))\n",
    "            palets_cost += element[\"attributes\"][\"Price\"]\n",
    "\n",
    "        # Añade los nodos inicial y final a los conjuntos de nodos únicos\n",
    "        unique_origin_nodes.add(node_initial)\n",
    "        unique_destination_nodes.add(node_final)\n",
    "        \n",
    "        # Incrementa el conteo de operaciones y el número total de palets\n",
    "        operation_count += 1\n",
    "        palets_number += charge\n",
    "\n",
    "        return nodes_batch , edges_batch\n",
    "\n",
    "    # Manejo de excepciones en caso de que ocurra algún error durante el proceso\n",
    "    except Exception as e:\n",
    "        log_list += f\"Error durante la transferencia de {node_initial} a {node_final}: {str(e)}\\n\"\n",
    "        return [], []\n",
    "\n",
    "    except Exception as e:\n",
    "        error_message = f\"Error en la transferancia: {e}\\n\"\n",
    "        log_list += error_message\n",
    "        return error_message\n",
    "\n",
    "import random \n",
    "import string\n",
    "def generate_random_title(length=8):\n",
    "    return ''.join(random.choices(string.ascii_letters + string.digits, k=length))\n",
    "\n",
    "def generate_html():\n",
    "    random_title = generate_random_title()\n",
    "    return f\"\"\"\n",
    "    <html lang=\"en\">\n",
    "    <head>\n",
    "        <meta charset=\"UTF-8\">\n",
    "        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    </head>\n",
    "    <body>\n",
    "        <iframe width=\"875\" height=\"800\" src=\"{tigergraph_insights_map}\" title=\"{random_title}\" frameborder=\"0\"></iframe>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "\n",
    "def generate_html1():\n",
    "    random_title = generate_random_title()\n",
    "    return f\"\"\"\n",
    "    <html lang=\"en\">\n",
    "    <head>\n",
    "        <meta charset=\"UTF-8\">\n",
    "        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    </head>\n",
    "    <body>\n",
    "        <iframe width=\"800\" height=\"800\" src=\"{tigergraph_insights_map1}\" title=\"{random_title}\" frameborder=\"0\"></iframe>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "\n",
    "def generate_html800():\n",
    "    random_title = generate_random_title()\n",
    "    return f\"\"\"\n",
    "    <html lang=\"en\">\n",
    "    <head>\n",
    "        <meta charset=\"UTF-8\">\n",
    "        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    </head>\n",
    "    <body>\n",
    "        <iframe width=\"700\" height=\"800\" src=\"{tigergraph_insights_map}\" title=\"{random_title}\" frameborder=\"0\"></iframe>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "\n",
    "def generate_html1_800():\n",
    "    random_title = generate_random_title()\n",
    "    return f\"\"\"\n",
    "    <html lang=\"en\">\n",
    "    <head>\n",
    "        <meta charset=\"UTF-8\">\n",
    "        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    </head>\n",
    "    <body>\n",
    "        <iframe width=\"700\" height=\"800\" src=\"{tigergraph_insights_map1}\" title=\"{random_title}\" frameborder=\"0\"></iframe>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "\n",
    "def generate_html1000():\n",
    "    random_title = generate_random_title()\n",
    "    return f\"\"\"\n",
    "    <html lang=\"en\">\n",
    "    <head>\n",
    "        <meta charset=\"UTF-8\">\n",
    "        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    </head>\n",
    "    <body>\n",
    "        <iframe width=\"1000\" height=\"800\" src=\"{tigergraph_insights_map1}\" title=\"{random_title}\" frameborder=\"0\"></iframe>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "def reset_html():\n",
    "    new_html = generate_html()\n",
    "    return gr.HTML(value=new_html, visible=True)\n",
    "\n",
    "def reset_html1():\n",
    "    new_html = generate_html1()\n",
    "    return gr.HTML(value=new_html, visible=True)\n",
    "\n",
    "def reset_html1_1000():\n",
    "    new_html = generate_html1000()\n",
    "    return gr.HTML(value=new_html, visible=True)\n",
    "\n",
    "\n",
    "def reset_html_800():\n",
    "    new_html = generate_html800()\n",
    "    return gr.HTML(value=new_html, visible=True)\n",
    "\n",
    "def reset_html1_800():\n",
    "    new_html = generate_html1_800()\n",
    "    return gr.HTML(value=new_html, visible=True)\n",
    "\n",
    "\n",
    "# Thread safety\n",
    "lock = threading.Lock()\n",
    "\n",
    "\n",
    "def make_daily_movements(input_file, column_origin, column_destination, column_transfert):\n",
    "    # Variables globales para llevar un conteo de operaciones y otras métricas.\n",
    "    global operation_count, palets_number, palets_cost, unique_origin_nodes, unique_destination_nodes, log_list, nodes_batch_full, edges_batch_full, df\n",
    "    # Inicializa las variables globales.\n",
    "    operation_count = 0\n",
    "    palets_number = 0\n",
    "    palets_cost = 0\n",
    "    unique_origin_nodes = set()\n",
    "    unique_destination_nodes = set()\n",
    "    log_list = \" \"\n",
    "    nodes_batch_full = []\n",
    "    edges_batch_full = []\n",
    "\n",
    "    # Lee el archivo CSV en un DataFrame.\n",
    "    df = pd.read_csv(input_file)\n",
    "\n",
    "    # Función para realizar la transferencia de volumen entre nodos.\n",
    "    def perform_transfer(row):\n",
    "        global log_list\n",
    "        try:\n",
    "            # Obtiene el origen, destino y volumen de la fila del DataFrame.\n",
    "            origin = str(row[column_origin])\n",
    "            destination = str(row[column_destination])\n",
    "            volume = float(row[column_transfert])\n",
    "            \n",
    "            # Llama a la función para obtener nodos y aristas actualizados.\n",
    "            nodes_batch, edges_batch = transfert_nodes_and_edges(origin, destination, volume)\n",
    "            \n",
    "            # Usa un lock para asegurar que las actualizaciones a las listas sean seguras en un entorno multihilo.\n",
    "            with lock:\n",
    "                add_or_update_final_nodes_batch(nodes_batch_full, nodes_batch, volume)\n",
    "                add_or_update_final_edges_batch(edges_batch_full, edges_batch, volume)\n",
    "                \n",
    "            # Incrementa el conteo de operaciones y otras métricas.\n",
    "            global operation_count, palets_number, palets_cost\n",
    "            operation_count += 1\n",
    "            palets_number += volume\n",
    "            palets_cost += volume * some_cost_per_palet  # Asumiendo que hay un costo por palet que debe definirse.\n",
    "            unique_origin_nodes.add(origin)\n",
    "            unique_destination_nodes.add(destination)\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Registra un error en caso de que la transferencia falle.\n",
    "            error_message = f\"{origin} hasta {destination}, no camino posible.\\n\"\n",
    "            log_list += error_message\n",
    "\n",
    "    # Usa un ThreadPoolExecutor para procesar las transferencias en paralelo.\n",
    "    with ThreadPoolExecutor(max_workers=1000) as executor:\n",
    "        # Crea y envía tareas para cada fila del DataFrame.\n",
    "        futures = [executor.submit(perform_transfer, row) for index, row in df.iterrows()]\n",
    "        for future in as_completed(futures):\n",
    "            pass  # Aquí se puede manejar el resultado de cada tarea si es necesario.\n",
    "\n",
    "    # Actualiza los nodos y aristas en la base de datos con los datos acumulados.\n",
    "    conn.upsertVertices(\"Nodes\", nodes_batch_full)\n",
    "    nodetype = \"Nodes\"\n",
    "    edgetype = \"distribute_to\"\n",
    "    conn.upsertEdges(sourceVertexType=nodetype, targetVertexType=nodetype, edgeType=edgetype, edges=edges_batch_full)\n",
    "    \n",
    "    # Actualiza el gráfico con el estado actual y obtiene el estado.\n",
    "    state_log = actualize_graph_carga(conn)\n",
    "\n",
    "    # Si no hubo errores, actualiza el mensaje de log.\n",
    "    if log_list == \" \":\n",
    "        log_list = \"All operations were successful.\"\n",
    "\n",
    "    return (\n",
    "        log_list,   #lista de los logs para el gradio\n",
    "        reset_html(),  # esta función devuelve HTML para reiniciar el mapa tigergraph.\n",
    "        gr.Button(\"Recargar mapa\", elem_classes=\"otherbutton\", visible=True),       #Elementos de Gradio\n",
    "        gr.Number(label=\"KPI : Numero de operaciones\", value=operation_count, visible=True, elem_classes=\"dropdown\"),\n",
    "        gr.Number(label=\"KPI : Numero de palets\", value=palets_number, visible=True, elem_classes=\"dropdown\"),\n",
    "        gr.Number(label=\"KPI : Numero de origen\", value=len(unique_origin_nodes), visible=True, elem_classes=\"dropdown\"),\n",
    "        gr.Number(label=\"KPI : Destinaciones diferentes\", value=len(unique_destination_nodes), visible=True, elem_classes=\"dropdown\"),\n",
    "        gr.Number(label=\"KPI : Coste total\", value=palets_cost, visible=True, elem_classes=\"dropdown\"),\n",
    "        gr.Number(label=\"KPI : Coste por palet\", value=round(palets_cost / palets_number, 1), visible=True, elem_classes=\"dropdown\")\n",
    "    )\n",
    "\n",
    "def make_daily_movements1(input_file, column_origin, column_destination, column_transfert):\n",
    "    global operation_count1, palets_number1, palets_cost1, unique_origin_nodes1, unique_destination_nodes1, log_list1, nodes_batch_full1\n",
    "    operation_count1 = 0\n",
    "    palets_number1 = 0\n",
    "    palets_cost1 = 0\n",
    "    unique_origin_nodes1 = set()\n",
    "    unique_destination_nodes1 = set()\n",
    "    log_list1 = \" \"\n",
    "    nodes_batch_full1 = []\n",
    "    edges_batch_full1 = []\n",
    "\n",
    "    df = pd.read_csv(input_file)\n",
    "\n",
    "    def perform_transfer1(row):\n",
    "        global log_list1\n",
    "        try:\n",
    "            origin = str(row[column_origin])\n",
    "            destination = str(row[column_destination])\n",
    "            volume = float(row[column_transfert])\n",
    "            nodes_batch1, edges_batch1 = transfert_nodes_and_edges1(origin, destination, volume)\n",
    "            with lock:\n",
    "                add_or_update_final_nodes_batch(nodes_batch_full1, nodes_batch1, volume)\n",
    "                add_or_update_final_edges_batch(edges_batch_full1, edges_batch1, volume)\n",
    "        except Exception as e:\n",
    "            error_message = f\"{origin} to {destination}: No existe ninguna conexión. \\n\"\n",
    "            log_list1 += error_message\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=1000) as executor:\n",
    "        futures = [executor.submit(perform_transfer1, row) for index, row in df.iterrows()]\n",
    "        for future in as_completed(futures):\n",
    "            pass\n",
    "\n",
    "    conn1.upsertVertices(\"Nodes\", nodes_batch_full1)\n",
    "    nodetype = \"Nodes\"\n",
    "    edgetype = \"distribute_to\"\n",
    "    conn1.upsertEdges(sourceVertexType=nodetype, targetVertexType=nodetype, edgeType=edgetype, edges=edges_batch_full1)\n",
    "    results = actualize_graph_carga(conn)\n",
    "    results1 = actualize_graph_carga(conn1)\n",
    "    #Results looks like that : \n",
    "        # {\"logs\": logs_state_nodes_and_arristas,\n",
    "        # \"node_counts\": node_counts,\n",
    "        # \"arista_counts\": arista_counts}\n",
    "\n",
    "    KPI_red_modificada = get_KPI(conn1, \"distribute_to\", \"Nodes\")\n",
    "\n",
    "    return (log_list1,\n",
    "        gr.Markdown(\"# Mapa red original\",visible=True,elem_classes = \"cabecero\"),reset_html_800(),gr.Button(\"Recargar mapa\",visible=True,elem_classes='otherbutton'),\n",
    "        gr.Markdown(\"# Mapa red modificada\",visible=True,elem_classes = \"cabecero\"),reset_html1_800(), gr.Button(\"Recargar mapa\",visible=True,elem_classes='otherbutton'),\n",
    "        # KPI RED ORIGINAL\n",
    "        gr.Markdown(\"# Red original\",visible=True,elem_classes='cabecero'),\n",
    "        gr.Number(label=\"Cantidad de Aristas\",value=numEdges,visible=True , elem_classes=\"dropdown\"),                                 \n",
    "        gr.Number(label=\"Cantidad de Nodos\",value = numNodes,visible=True, elem_classes=\"dropdown\"),\n",
    "        gr.Number(label= \"Capacidad media por arista\",value = avg_capacity/2,visible=True, elem_classes=\"dropdown\"),\n",
    "        gr.Number(label=\"Capacidad total de las aristas \",value = total_capacity_edges/2,visible=True, elem_classes=\"dropdown\"),\n",
    "        gr.Number(label= \"Capacidad total de los Almacenes\",value = total_capacity_warehouse,visible=True, elem_classes=\"dropdown\"),\n",
    "        gr.Number(label=\"Stock total de los almacenes\",value = total_stock,visible=True, elem_classes=\"dropdown\"),\n",
    "        # KPI ENTREGA ORIGINAL\n",
    "        gr.Markdown(\"# Entrega original\",visible=True,elem_classes='cabecero'),\n",
    "        gr.Number(label=\"Numero de operaciones\", value = operation_count,visible=True, elem_classes=\"dropdown\"),                    \n",
    "        gr.Number(label=\"Numero de palets\",value = palets_number, visible=True, elem_classes=\"dropdown\"), \n",
    "        gr.Number(label=\"Numero de origen\",value = len(unique_origin_nodes), visible=True, elem_classes=\"dropdown\"), \n",
    "        gr.Number(label=\"Destinaciones diferentes\",value = len(unique_destination_nodes), visible=True, elem_classes=\"dropdown\"), \n",
    "        gr.Number(label=\"Coste total\",value = palets_cost, visible=True, elem_classes=\"dropdown\"), \n",
    "        gr.Number(label=\"Coste por palet\",value = round(palets_cost/palets_number,1), visible=True, elem_classes=\"dropdown\"),\n",
    "        # KPI RED SIMULADA\n",
    "        gr.Markdown(\"# Red modificada\",visible=True,elem_classes='cabecero'),\n",
    "        gr.Number(label=\"Cantidad de Aristas\", value=KPI_red_modificada[\"num_edges\"], visible=True, elem_classes=\"dropdown\"),\n",
    "        gr.Number(label=\"Cantidad de Nodos\", value=KPI_red_modificada[\"num_nodes\"], visible=True, elem_classes=\"dropdown\"),\n",
    "        gr.Number(label=\"Capacidad media por arista\", value=KPI_red_modificada[\"avg_capacity\"], visible=True, elem_classes=\"dropdown\"),\n",
    "        gr.Number(label=\"Capacidad total de las aristas\", value=KPI_red_modificada[\"total_capacity_edges\"], visible=True, elem_classes=\"dropdown\"),\n",
    "        gr.Number(label=\"Capacidad total de los Almacenes\", value=KPI_red_modificada[\"total_capacity_warehouses\"], visible=True, elem_classes=\"dropdown\"),\n",
    "        gr.Number(label=\"Stock total de los almacenes\", value=KPI_red_modificada[\"total_stock\"], visible=True, elem_classes=\"dropdown\"),\n",
    "        # KPI ENTREGA SIMULADA\n",
    "        gr.Markdown(\"# Entrega modificada\",visible=True,elem_classes='cabecero'),\n",
    "        gr.Number(label=\"Numero de operaciones\", value = operation_count1,visible=True, elem_classes=\"dropdown\"),                    \n",
    "        gr.Number(label=\"Numero de palets\",value = palets_number1, visible=True, elem_classes=\"dropdown\"), \n",
    "        gr.Number(label=\"Numero de origen\",value = len(unique_origin_nodes1), visible=True, elem_classes=\"dropdown\"), \n",
    "        gr.Number(label=\"Destinaciones diferentes\",value = len(unique_destination_nodes1), visible=True, elem_classes=\"dropdown\"), \n",
    "        gr.Number(label=\"Coste total\",value = palets_cost1, visible=True, elem_classes=\"dropdown\"), \n",
    "        gr.Number(label=\"Coste por palet\",value = round(palets_cost1/palets_number1,1), visible=True, elem_classes=\"dropdown\"),\n",
    "        gr.Textbox(value=results[\"logs\"], label=\"Estado de la red\", visible=True,lines=2,max_lines=10, elem_classes=\"dropdown\"),\n",
    "        gr.Textbox(value=results[\"node_counts\"][\"Sobrecargado\"], label=\"Nodos sobrecargados\", visible=True, elem_classes=\"dropdown\"),\n",
    "        gr.Textbox(value=results[\"node_counts\"][\"Subcargado\"], label=\"Nodos subcargados\", visible=True, elem_classes=\"dropdown\"),\n",
    "        gr.Textbox(value=int(round(results[\"arista_counts\"][\"Sobrecargado\"]/2,0)), label=\"Aristas sobrecargadas\", visible=True, elem_classes=\"dropdown\"),  #Divide by 2 to take into account the fact that the edges are bidirectional\n",
    "        gr.Textbox(value=int(round(results[\"arista_counts\"][\"Subcargado\"]/2,0)), label=\"Aristas subcargadas\", visible=True, elem_classes=\"dropdown\"),\n",
    "        gr.Textbox(value=results1[\"logs\"], label=\"Estado de la red\", visible=True,lines=2,max_lines=10, elem_classes=\"dropdown\"),\n",
    "        gr.Textbox(value=results1[\"node_counts\"][\"Sobrecargado\"], label=\"Nodos sobrecargados\", visible=True, elem_classes=\"dropdown\"),\n",
    "        gr.Textbox(value=results1[\"node_counts\"][\"Subcargado\"], label=\"Nodos subcargados\", visible=True, elem_classes=\"dropdown\"),\n",
    "        gr.Textbox(value=int(round(results1[\"arista_counts\"][\"Sobrecargado\"]/2,0)), label=\"Aristas sobrecargadas\", visible=True, elem_classes=\"dropdown\"),  #Divide by 2 to take into account the fact that the edges are bidirectional\n",
    "        gr.Textbox(value=int(round(results1[\"arista_counts\"][\"Subcargado\"]/2,0)), label=\"Aristas subcargadas\", visible=True, elem_classes=\"dropdown\"),\n",
    "        gr.Number(label = \"Precio de la entrega mejorada de % \", value = int(((palets_cost-palets_cost1)/palets_cost)*100), visible=True, elem_classes=\"dropdown\"),\n",
    "        gr.Number(label=\"Porcentaje\",elem_classes=\"dropdown\",visible=True),\n",
    "        gr.Button(\"Subir carga\",elem_classes=\"otherbutton\",visible=True),\n",
    "        gr.Button(\"Bajar carga\",elem_classes=\"otherbutton\",visible=True)\n",
    "\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def transfert_nodes_and_edges1(node_initial, node_final, charge, weight_attribute=\"Capacity\", nodetype=\"Nodes\", edgetype=\"distribute_to\"):\n",
    "    global operation_count1, palets_number1, palets_cost1, unique_origin_nodes1, unique_destination_nodes1, log_list1, nodes_batch_full1\n",
    "    results_astar = conn1.runInstalledQuery(\"tg_astar_test\", params={\n",
    "        \"source_vertex\": node_final, \"source_vertex.type\": nodetype,\n",
    "        \"target_vertex\": node_initial, \"target_vertex.type\": nodetype,\n",
    "        \"e_type_set\": edgetype, \"weight_type\": \"FLOAT\",\n",
    "        \"latitude\": \"latitude\", \"longitude\": \"longitude\",\n",
    "        \"weight_attribute\": weight_attribute,\n",
    "        \"print_stats\": \"True\"\n",
    "    })\n",
    "    \n",
    "    order_taken = path_taken(results_astar)\n",
    "    edge_set = results_astar[2]['@@display_edge_set']\n",
    "    reordered_edges_set = []\n",
    "    for location in order_taken:\n",
    "        for edge in edge_set:\n",
    "            if edge['from_id'] == location:\n",
    "                reordered_edges_set.append(edge)\n",
    "\n",
    "    node_set = results_astar[2]['tmp']\n",
    "    reordered_nodes_set = []\n",
    "    for location in order_taken:\n",
    "        for item in node_set:\n",
    "            if item['v_id'] == location:\n",
    "                reordered_nodes_set.append(item)\n",
    "\n",
    "    try:\n",
    "        node_i_stock = reordered_nodes_set[0][\"attributes\"][\"Stock\"]\n",
    "        node_f_stock = reordered_nodes_set[-1][\"attributes\"][\"Stock\"]\n",
    "        node_i_unload_capacity = reordered_nodes_set[0][\"attributes\"][\"UnloadCapacity\"]\n",
    "        node_f_load_capacity = reordered_nodes_set[-1][\"attributes\"][\"LoadCapacity\"]\n",
    "\n",
    "        if charge > node_i_stock:\n",
    "            error_message = f\"{node_initial} hasta {node_final}: No hay suficientes inventario ({charge} > {node_i_stock})\\n\"\n",
    "            log_list1 += error_message\n",
    "\n",
    "        if charge > node_f_load_capacity:\n",
    "            error_message = f\"{node_initial} hasta {node_final}: No hay suficiente capacidad de carga en el almacén de recepción (charge: {charge} > LoadCapacity: {node_f_load_capacity})\\n\"\n",
    "            log_list1 += error_message\n",
    "\n",
    "        if charge > node_i_unload_capacity:\n",
    "            error_message = f\"{node_initial} hasta {node_final}: No hay suficiente capacidad de descarga desde el almacén de salida (charge: {charge} > UnloadCapacity: {node_i_unload_capacity})\\n\"\n",
    "            log_list1 += error_message\n",
    "\n",
    "        capacity_edge = reordered_edges_set[0][\"attributes\"][\"Capacity\"]\n",
    "        daily_movement = reordered_edges_set[0][\"attributes\"][\"Daily_movement\"]\n",
    "\n",
    "        if daily_movement + charge > capacity_edge:\n",
    "            error_message = f\"Enviar {charge} palets desde {node_initial} hasta {node_final}: Capacidad de la arista insuficiente ({daily_movement + charge} > {capacity_edge})\\n\"\n",
    "            log_list1 += error_message\n",
    "\n",
    "        nodes_batch = [\n",
    "            (node_initial, {\"Stock\": node_i_stock - charge}),\n",
    "            (node_final, {\"Stock\": node_f_stock + charge})\n",
    "        ]\n",
    "\n",
    "        edges_batch = []\n",
    "        for element in reordered_edges_set:\n",
    "            element['attributes']['Daily_movement'] += charge\n",
    "            edges_batch.append((element[\"from_id\"], element[\"to_id\"], {\"Daily_movement\": element[\"attributes\"][\"Daily_movement\"]}))\n",
    "            palets_cost1 += element[\"attributes\"][\"Price\"]\n",
    "\n",
    "        unique_origin_nodes1.add(node_initial)\n",
    "        unique_destination_nodes1.add(node_final)\n",
    "        operation_count1 += 1\n",
    "        palets_number1 += charge\n",
    "\n",
    "        return nodes_batch , edges_batch\n",
    "\n",
    "    except Exception as e:\n",
    "        error_message = f\"Error en la transferancia: {e} \\n\"\n",
    "        log_list1 += error_message\n",
    "        return error_message\n",
    "# log_messages = make_daily_movements(r\"C:\\Users\\JulienRigot\\OneDrive - LIS Data Solutions\\Escritorio\\code_GORDIAS\\base de datos graph\\Tigergraph\\CSV_entrega\\entrega_demo.csv\", \"CODE_Origin\", \"CODE_Destination\", \"Palets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funciones de modificacion de red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "global logs_modif_network\n",
    "logs_modif_network = \" \"\n",
    "\n",
    "\n",
    "# ADD NODES \n",
    "\n",
    "def add_node(id, attributes_dict=None, vertex_type=\"Nodes\"):\n",
    "    global logs_modif_network\n",
    "    if attributes_dict is None:\n",
    "        conn1.upsertVertex(vertex_type, id)\n",
    "        message =  f\"Nodo {id} añadido\\n\"\n",
    "        logs_modif_network +=message\n",
    "        return logs_modif_network\n",
    "    else:\n",
    "        attributes = json.loads(attributes_dict)\n",
    "        conn1.upsertVertex(vertex_type, id, attributes=attributes)\n",
    "        message =  f\"Nodo {id} añadido with attributos : {attributes} \\n\"\n",
    "        logs_modif_network +=message\n",
    "    return logs_modif_network\n",
    "\n",
    "def get_values_nodes(*args):\n",
    "    values = {key: val for key, val in zip(atributes_nodes.keys(), args)}\n",
    "    return values\n",
    "\n",
    "def get_values_edges(*args):\n",
    "    values = {key: val for key, val in zip(atributes_edges.keys(), args)}\n",
    "    return values[\"Capacity\"]\n",
    "\n",
    "\n",
    "def add_node_with_values(id, *args):\n",
    "    attributes = get_values_nodes(*args)\n",
    "    attributes_json = json.dumps(attributes)\n",
    "    actualize_graph_carga(conn)\n",
    "    return add_node(id, attributes_json), reset_html1()\n",
    "\n",
    "\n",
    "\n",
    "# ADD EDGES \n",
    "def add_new_edge(source_vertex_id, target_vertex_id, attributes_dict=None,source_vertex_type=\"Nodes\",target_vertex_type = \"Nodes\", edge_type=\"distribute_to\"):\n",
    "    global logs_modif_network\n",
    "    if attributes_dict is None:\n",
    "        conn1.upsertEdge(source_vertex_type, source_vertex_id, edge_type, target_vertex_type, target_vertex_id)\n",
    "        actualize_graph_carga(conn)\n",
    "        message =  f\"Arista de {source_vertex_id} hasta {target_vertex_id}  añadida\"\n",
    "        logs_modif_network += message\n",
    "        return logs_modif_network\n",
    "    else:\n",
    "        attributes = json.loads(attributes_dict)\n",
    "        actualize_graph_carga(conn)\n",
    "        conn1.upsertEdge(source_vertex_type, source_vertex_id, edge_type, target_vertex_type, target_vertex_id, attributes=attributes)\n",
    "        message =  f\"Arista de {source_vertex_id} hasta {target_vertex_id} añadida con los atributos siguientes: {attributes} \\n\"\n",
    "        logs_modif_network += message\n",
    "    return logs_modif_network\n",
    "\n",
    "def add_edge_with_values(source_vertex_id, target_vertex_id, *args):\n",
    "    attributes = get_values_edges(*args)\n",
    "    attributes_json = json.dumps(attributes)\n",
    "    return add_new_edge(source_vertex_id,target_vertex_id, attributes_json), reset_html1()\n",
    "\n",
    "# GET ATTRIBUTES\n",
    "attributes_nodes_list = []\n",
    "attributes_edges_list = []\n",
    "conex_nodes_list = conn1.getVertexAttrs('Nodes')\n",
    "conex_edges_list = conn1.getEdgeAttrs('distribute_to')\n",
    "\n",
    "for node in conex_nodes_list:\n",
    "    attributes_nodes_list.append(node[0])\n",
    "\n",
    "\n",
    "for edge in conex_edges_list:\n",
    "    attributes_edges_list.append(edge[0])\n",
    "\n",
    "\n",
    "#Remove carga atributes as it is here only for a cheat with colors of the tigergraph map. no need to change that\n",
    "if 'Carga' in attributes_nodes_list:\n",
    "    attributes_nodes_list.remove('Carga')\n",
    "\n",
    "if 'Carga' in attributes_edges_list:\n",
    "    attributes_edges_list.remove('Carga')\n",
    "\n",
    "\n",
    "# GET NODES NAMES\n",
    "list_name_nodes = []\n",
    "name_nodes_conn = conn1.getVertices(\"Nodes\")\n",
    "for i in range(0, len(name_nodes_conn)):\n",
    "    list_name_nodes.append(name_nodes_conn[i][\"v_id\"])\n",
    "\n",
    "def add_edge(source_vertex_id, target_vertex_id, attributes_dict=None, vertex_type=\"Nodes\", edgeType=\"distribute_to\"):\n",
    "    global logs_modif_network\n",
    "    if attributes_dict is None:\n",
    "        conn1.upsertEdge(sourceVertexType=vertex_type,\n",
    "                        targetVertexType=vertex_type,\n",
    "                        edgeType=edgeType,\n",
    "                        sourceVertexId=source_vertex_id,\n",
    "                        targetVertexId=target_vertex_id)\n",
    "        message =  f\"Arista desde {source_vertex_id} hasta {target_vertex_id} añadido\\n\"\n",
    "        logs_modif_network +=message\n",
    "        return logs_modif_network\n",
    "    else:\n",
    "        attributes = json.loads(attributes_dict)\n",
    "        conn1.upsertEdge(sourceVertexType=vertex_type,\n",
    "                        targetVertexType=vertex_type,\n",
    "                        edgeType=edgeType,\n",
    "                        sourceVertexId=source_vertex_id,\n",
    "                        targetVertexId=target_vertex_id,\n",
    "                        attributes=attributes)\n",
    "        message =  f\"Arista {source_vertex_id} hasta {target_vertex_id} añadido con los atributos siguientes : {attributes} \\n\"\n",
    "        logs_modif_network +=message\n",
    "        return logs_modif_network\n",
    "\n",
    "\n",
    "#Erase Data\n",
    "\n",
    "def erase_edge(source_vertex_id, target_vertex_id, vertex_type=\"Nodes\", edgeType=\"distribute_to\"):\n",
    "    global logs_modif_network\n",
    "    result = conn1.delEdges(sourceVertexType=vertex_type,\n",
    "                           targetVertexType=vertex_type,\n",
    "                           edgeType=edgeType,\n",
    "                           sourceVertexId=source_vertex_id,\n",
    "                           targetVertexId=target_vertex_id)\n",
    "    \n",
    "    if result == {edgeType: 0}:\n",
    "        message = f\"Arista de {source_vertex_id} hacia {target_vertex_id} no existe o no ha podido borrarse\\n\"\n",
    "    else:\n",
    "        message = f\"Arista de  {source_vertex_id} hacia {target_vertex_id} borrada \\n\"\n",
    "    \n",
    "    logs_modif_network += message\n",
    "    return logs_modif_network , reset_html1()\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def erase_node(id, vertex_type=\"Nodes\"):\n",
    "    global logs_modif_network\n",
    "    result = conn1.delVerticesById(vertexIds=id, vertexType=vertex_type)\n",
    "    \n",
    "    if result == 0:\n",
    "        message = f\"Nodo {id} no existe o no ha podido borrarse\\n\"\n",
    "    else:\n",
    "        message = f\"Nodo {id} borrado\\n\"\n",
    "    \n",
    "    logs_modif_network += message\n",
    "    return logs_modif_network , reset_html1()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# add_edge_with_values(\"Las Palmas de Gran Canaria\",\"Seville\",{\"Capacity\": 0, \"Daily_movement\": 0, \"Price\": 0})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tab modif cargas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def increase_charge(conn, percentage):\n",
    "    aristas = conn.getEdgesByType(edgeType=\"distribute_to\")\n",
    "    new_charges = []\n",
    "    for arista in aristas:\n",
    "        current_charge = arista[\"attributes\"][\"Daily_movement\"]\n",
    "        new_charge = current_charge * (1 + percentage / 100)\n",
    "        arista[\"attributes\"][\"Daily_movement\"] = new_charge\n",
    "        new_charges.append((arista[\"from_id\"], arista[\"to_id\"], {\"Daily_movement\": new_charge}))\n",
    "\n",
    "    return new_charges\n",
    "\n",
    "\n",
    "def decrease_charge(conn, percentage):\n",
    "    aristas = conn.getEdgesByType(edgeType=\"distribute_to\")\n",
    "    new_charges = []\n",
    "    logs_state_aristas = \"\"\n",
    "    arista_counts = {\"Sobrecargado\": 0, \"Subcargado\": 0, \"Optimal\": 0}\n",
    "\n",
    "    for arista in aristas:\n",
    "        current_charge = arista[\"attributes\"][\"Daily_movement\"]\n",
    "        capacity_edge = arista[\"attributes\"][\"Capacity\"]\n",
    "        new_charge = current_charge * (1 - percentage / 100)\n",
    "        arista[\"attributes\"][\"Daily_movement\"] = new_charge\n",
    "        \n",
    "        if capacity_edge == 0:\n",
    "            nivel_arista = \"No definido\"\n",
    "        else:\n",
    "            if (new_charge / capacity_edge) > 1:\n",
    "                nivel_arista = \"Sobrecargado\"\n",
    "                arista_counts[\"Sobrecargado\"] += 1\n",
    "                logs_state_aristas += f\"⚠️ La arista {arista['from_id']} hasta {arista['to_id']} es {nivel_arista} con un movimiento diario de {new_charge}\\n\"\n",
    "            elif 0.7 < (new_charge / capacity_edge) <= 1:\n",
    "                nivel_arista = \"Optimal\"\n",
    "                arista_counts[\"Optimal\"] += 1\n",
    "            else:\n",
    "                nivel_arista = \"Subcargado\"\n",
    "                arista_counts[\"Subcargado\"] += 1\n",
    "\n",
    "        new_charges.append((arista[\"from_id\"], arista[\"to_id\"], {\"Daily_movement\": new_charge, \"Carga\": nivel_arista}))\n",
    "\n",
    "    if logs_state_aristas == \"\":\n",
    "        logs_state_aristas = \"Aucune arista n'est surchargée.\"\n",
    "\n",
    "    results = {\n",
    "        \"logs\": logs_state_aristas,\n",
    "        \"arista_counts\": arista_counts,\n",
    "    }\n",
    "\n",
    "    return results , new_charges\n",
    "\n",
    "def update_batch_increase(conn,percentage):\n",
    "    batch = increase_charge(conn, percentage)\n",
    "    conn.upsertEdges(sourceVertexType=\"Nodes\", targetVertexType=\"Nodes\", edgeType=\"distribute_to\", edges=batch)\n",
    "\n",
    "def update_batch_decrease(conn,percentage):\n",
    "    logs , batch = decrease_charge(conn, percentage)\n",
    "    conn.upsertEdges(sourceVertexType=\"Nodes\", targetVertexType=\"Nodes\", edgeType=\"distribute_to\", edges=batch)\n",
    "\n",
    "    # return(gr.Textbox(value=logs[\"logs\"], label=\"Estado de la red\", visible=True,lines=2,max_lines=10, elem_classes=\"dropdown\"),\n",
    "    #     gr.Textbox(value=logs[\"node_counts\"][\"Sobrecargado\"], label=\"Nodos sobrecargados\", visible=True, elem_classes=\"dropdown\"),\n",
    "    #     gr.Textbox(value=logs[\"node_counts\"][\"Subcargado\"], label=\"Nodos subcargados\", visible=True, elem_classes=\"dropdown\"),\n",
    "    #     gr.Textbox(value=int(round(logs[\"arista_counts\"][\"Sobrecargado\"]/2,0)), label=\"Aristas sobrecargadas\", visible=True, elem_classes=\"dropdown\"),  #Divide by 2 to take into account the fact that the edges are bidirectional\n",
    "    #     gr.Textbox(value=int(round(logs[\"arista_counts\"][\"Subcargado\"]/2,0)), label=\"Aristas subcargadas\", visible=True, elem_classes=\"dropdown\"))\n",
    "\n",
    "\n",
    "\n",
    "# a = update_batch_decrease(conn,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_daily_movements_with_percentages_positive(input_file, column_origin, column_destination, column_transfert,percentage):\n",
    "    global operation_count3, palets_number3, palets_cost3, unique_origin_nodes, unique_destination_nodes, log_list, nodes_batch_full2,edges_batch_full2,df\n",
    "    operation_count3 = 0\n",
    "    palets_number3 = 0\n",
    "    palets_cost3 = 0\n",
    "    unique_origin_nodes = set()\n",
    "    unique_destination_nodes = set()\n",
    "    log_list = \" \"\n",
    "    nodes_batch_full2 = []\n",
    "    edges_batch_full2 = []\n",
    "\n",
    "    df = pd.read_csv(input_file)\n",
    "\n",
    "    def perform_transfer(row):\n",
    "        global log_list\n",
    "        try:\n",
    "            origin = str(row[column_origin])\n",
    "            destination = str(row[column_destination])\n",
    "            positive_or_negative = \"positive\"\n",
    "            if positive_or_negative == \"positive\":\n",
    "                volume = float(row[column_transfert]) * (percentage / 100)\n",
    "            if positive_or_negative == \"negative\":\n",
    "                volume = float(row[column_transfert]) * (1 - percentage / 100)\n",
    "            nodes_batch, edges_batch = transfert_nodes_and_edges1(origin, destination, volume)\n",
    "            with lock:\n",
    "                add_or_update_final_nodes_batch(nodes_batch_full2, nodes_batch, volume)\n",
    "                add_or_update_final_edges_batch(edges_batch_full2, edges_batch, volume)\n",
    "        except Exception as e:\n",
    "            error_message = f\"{origin} hasta {destination}, no camino posible.\\n\"\n",
    "            log_list += error_message\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=1000) as executor:\n",
    "        futures = [executor.submit(perform_transfer, row) for index, row in df.iterrows()]\n",
    "        for future in as_completed(futures):\n",
    "            pass\n",
    "\n",
    "    conn1.upsertVertices(\"Nodes\", nodes_batch_full2)\n",
    "    nodetype = \"Nodes\"\n",
    "    edgetype = \"distribute_to\"\n",
    "    conn1.upsertEdges(sourceVertexType=nodetype, targetVertexType=nodetype, edgeType=edgetype, edges=edges_batch_full2)\n",
    "    results2 = actualize_graph_carga(conn1)\n",
    "\n",
    "    if log_list == \" \":\n",
    "        log_list = \"All operations were successful.\"\n",
    "\n",
    "    return (reset_html1(),\n",
    "        gr.Textbox(value=results2[\"logs\"], label=\"Estado de la red\", visible=True,lines=2,max_lines=10, elem_classes=\"dropdown\"),\n",
    "        gr.Textbox(value=results2[\"node_counts\"][\"Sobrecargado\"], label=\"Nodos sobrecargados\", visible=True, elem_classes=\"dropdown\"),\n",
    "        gr.Textbox(value=results2[\"node_counts\"][\"Subcargado\"], label=\"Nodos subcargados\", visible=True, elem_classes=\"dropdown\"),\n",
    "        gr.Textbox(value=int(round(results2[\"arista_counts\"][\"Sobrecargado\"]/2,0)), label=\"Aristas sobrecargadas\", visible=True, elem_classes=\"dropdown\"),  #Divide by 2 to take into account the fact that the edges are bidirectional\n",
    "        gr.Textbox(value=int(round(results2[\"arista_counts\"][\"Subcargado\"]/2,0)), label=\"Aristas subcargadas\", visible=True, elem_classes=\"dropdown\")\n",
    "        )\n",
    "    # return (log_list, reset_html(), gr.Button(\"Recargar mapa\",elem_classes=\"otherbutton\",visible=True),\n",
    "    #     gr.Number(label=\"KPI : Numero de operaciones\", value = operation_count,visible=True,elem_classes=\"dropdown\"), \n",
    "    #     gr.Number(label=\"KPI : Numero de palets\",value = palets_number, visible=True,elem_classes=\"dropdown\"), \n",
    "    #     gr.Number(label=\"KPI : Numero de origen\",value = len(unique_origin_nodes), visible=True,elem_classes=\"dropdown\"), \n",
    "    #     gr.Number(label=\"KPI : Destinaciones diferentes\",value = len(unique_destination_nodes), visible=True,elem_classes=\"dropdown\"), \n",
    "    #     gr.Number(label=\"KPI : Coste total\",value = palets_cost, visible=True,elem_classes=\"dropdown\"), \n",
    "    #     gr.Number(label=\"KPI : Coste por palet\",value = round(palets_cost/palets_number,1), visible=True,elem_classes=\"dropdown\"))\n",
    "\n",
    "def make_daily_movements_with_percentages_negative(input_file, column_origin, column_destination, column_transfert,percentage):\n",
    "    global operation_count3, palets_number3, palets_cost3, unique_origin_nodes, unique_destination_nodes, log_list, nodes_batch_full2,edges_batch_full2,df\n",
    "    operation_count3 = 0\n",
    "    palets_number3 = 0\n",
    "    palets_cost3 = 0\n",
    "    unique_origin_nodes = set()\n",
    "    unique_destination_nodes = set()\n",
    "    log_list = \" \"\n",
    "    nodes_batch_full2 = []\n",
    "    edges_batch_full2 = []\n",
    "\n",
    "    df = pd.read_csv(input_file)\n",
    "\n",
    "    def perform_transfer(row):\n",
    "        global log_list\n",
    "        try:\n",
    "            origin = str(row[column_origin])\n",
    "            destination = str(row[column_destination])\n",
    "            positive_or_negative = \"negative\"\n",
    "            if positive_or_negative == \"positive\":\n",
    "                volume = float(row[column_transfert]) * (percentage / 100)\n",
    "            if positive_or_negative == \"negative\":\n",
    "                volume = float(row[column_transfert]) * (1 - percentage / 100)\n",
    "            nodes_batch, edges_batch = transfert_nodes_and_edges1(origin, destination, volume)\n",
    "            with lock:\n",
    "                add_or_update_final_nodes_batch(nodes_batch_full2, nodes_batch, volume)\n",
    "                add_or_update_final_edges_batch(edges_batch_full2, edges_batch, volume)\n",
    "        except Exception as e:\n",
    "            error_message = f\"{origin} hasta {destination}, no camino posible.\\n\"\n",
    "            log_list += error_message\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=1000) as executor:\n",
    "        futures = [executor.submit(perform_transfer, row) for index, row in df.iterrows()]\n",
    "        for future in as_completed(futures):\n",
    "            pass\n",
    "\n",
    "    conn1.upsertVertices(\"Nodes\", nodes_batch_full2)\n",
    "    nodetype = \"Nodes\"\n",
    "    edgetype = \"distribute_to\"\n",
    "    conn1.upsertEdges(sourceVertexType=nodetype, targetVertexType=nodetype, edgeType=edgetype, edges=edges_batch_full2)\n",
    "    results2 = actualize_graph_carga(conn1)\n",
    "\n",
    "    if log_list == \" \":\n",
    "        log_list = \"All operations were successful.\"\n",
    "\n",
    "    return (reset_html1(),\n",
    "        gr.Textbox(value=results2[\"logs\"], label=\"Estado de la red\", visible=True,lines=2,max_lines=10, elem_classes=\"dropdown\"),\n",
    "        gr.Textbox(value=results2[\"node_counts\"][\"Sobrecargado\"], label=\"Nodos sobrecargados\", visible=True, elem_classes=\"dropdown\"),\n",
    "        gr.Textbox(value=results2[\"node_counts\"][\"Subcargado\"], label=\"Nodos subcargados\", visible=True, elem_classes=\"dropdown\"),\n",
    "        gr.Textbox(value=int(round(results2[\"arista_counts\"][\"Sobrecargado\"]/2,0)), label=\"Aristas sobrecargadas\", visible=True, elem_classes=\"dropdown\"),  #Divide by 2 to take into account the fact that the edges are bidirectional\n",
    "        gr.Textbox(value=int(round(results2[\"arista_counts\"][\"Subcargado\"]/2,0)), label=\"Aristas subcargadas\", visible=True, elem_classes=\"dropdown\")\n",
    "        )\n",
    "\n",
    "# a = make_daily_movements_with_percentages(r\"C:\\Users\\JulienRigot\\OneDrive - LIS Data Solutions\\Escritorio\\code_GORDIAS\\base de datos graph\\Tigergraph\\CSV_entrega\\df_1_move.csv\", \"CODE_Origin\", \"CODE_Destination\", \"Palets\",10,\"positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_path(input_file):\n",
    "    df = pd.read_csv(input_file.name)\n",
    "    target_column = sorted(list(df.columns))\n",
    "    return  gr.Dropdown(choices = target_column) , gr.Dropdown(choices = target_column) , gr.Dropdown(choices = target_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Value first tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_edge = \"distribute_to\"\n",
    "name_node = \"Nodes\"\n",
    "\n",
    "\n",
    "#######RED ORIGINAL######\n",
    "\n",
    "numEdges = conn.getEdgeCount(name_edge)\n",
    "numNodes = conn.getVertexCount(name_node)\n",
    "edge = conn.getEdgeStats(name_edge)\n",
    "avg_capacity = round(edge[name_edge]['Capacity']['AVG'],1)\n",
    "\n",
    "edges = conn.getEdgesByType(name_edge)\n",
    "total_capacity_edges = 0\n",
    "for warehouse in edges :\n",
    "    capacity_edges = warehouse[\"attributes\"][\"Capacity\"]     \n",
    "    total_capacity_edges += round(capacity_edges,1)\n",
    "\n",
    "almacenes = conn.getVertices(name_node)\n",
    "total_capacity_warehouse = 0\n",
    "for warehouse in almacenes :\n",
    "    capacity_edges = warehouse[\"attributes\"][\"Capacity\"]      \n",
    "    total_capacity_warehouse += round(capacity_edges,1)\n",
    "    total_capacity_warehouse = round(total_capacity_warehouse,1)\n",
    "\n",
    "almacen = conn.getVertices(name_node)\n",
    "total_stock = 0\n",
    "for warehouse in almacen :\n",
    "    stock = warehouse[\"attributes\"][\"Stock\"]     \n",
    "    total_stock += stock\n",
    "    total_stock = round(total_stock,0)\n",
    "\n",
    "capacity_per_edge = round(total_capacity_warehouse/numEdges,1)\n",
    "\n",
    "\n",
    "#######RED SIMULADA######\n",
    "import concurrent.futures\n",
    "\n",
    "def get_num_edges(conn, edge_name):\n",
    "    return conn.getEdgeCount(edge_name)\n",
    "\n",
    "def get_num_nodes(conn, node_name):\n",
    "    return conn.getVertexCount(node_name)\n",
    "\n",
    "def get_avg_capacity(conn, edge_name):\n",
    "    edges = conn.getEdgeStats(edge_name)\n",
    "    avg_capacity = edges[edge_name]['Capacity']['AVG']\n",
    "    return round(avg_capacity/2, 1)\n",
    "\n",
    "def get_total_capacity_edges(conn, edge_name):\n",
    "    edges = conn.getEdgesByType(edge_name)\n",
    "    total_capacity = 0\n",
    "    for edge in edges:\n",
    "        total_capacity += edge[\"attributes\"][\"Capacity\"]\n",
    "    return total_capacity /2\n",
    "\n",
    "def get_total_capacity_nodes(conn, node_name):\n",
    "    warehouses = conn.getVertices(node_name)\n",
    "    total_capacity = 0\n",
    "    for warehouse in warehouses:\n",
    "        total_capacity += warehouse[\"attributes\"][\"Capacity\"]\n",
    "    return round(total_capacity, 1)\n",
    "\n",
    "def get_total_stock(conn, node_name):\n",
    "    warehouses = conn.getVertices(node_name)\n",
    "    total_stock = 0\n",
    "    for warehouse in warehouses:\n",
    "        total_stock += warehouse[\"attributes\"][\"Stock\"]\n",
    "    return round(total_stock, 0)\n",
    "\n",
    "def get_capacity_per_edge(total_capacity_warehouses, num_edges):\n",
    "    if num_edges == 0:\n",
    "        return 0\n",
    "    return round(total_capacity_warehouses / num_edges, 0)\n",
    "\n",
    "def get_KPI(conn, edge_name, node_name):\n",
    "     with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        futures = {\n",
    "            \"num_edges\": executor.submit(get_num_edges, conn, edge_name),\n",
    "            \"num_nodes\": executor.submit(get_num_nodes, conn, node_name),\n",
    "            \"avg_capacity\": executor.submit(get_avg_capacity, conn, edge_name),\n",
    "            \"total_capacity_edges\": executor.submit(get_total_capacity_edges, conn, edge_name),\n",
    "            \"total_capacity_warehouses\": executor.submit(get_total_capacity_warehouses, conn, node_name),\n",
    "            \"total_stock\": executor.submit(get_total_stock, conn, node_name)\n",
    "        }\n",
    "\n",
    "        results = {name: future.result() for name, future in futures.items()}\n",
    "        results[\"capacity_per_edge\"] = get_capacity_per_edge(results[\"total_capacity_warehouses\"], results[\"num_edges\"])\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JulienRigot\\Projets\\zzEnvs\\Transport\\Lib\\site-packages\\gradio\\routes.py:1150: DeprecationWarning: \n",
      "        on_event is deprecated, use lifespan event handlers instead.\n",
      "\n",
      "        Read more about it in the\n",
      "        [FastAPI docs for Lifespan Events](https://fastapi.tiangolo.com/advanced/events/).\n",
      "        \n",
      "  @app.on_event(\"startup\")\n",
      "c:\\Users\\JulienRigot\\Projets\\zzEnvs\\Transport\\Lib\\site-packages\\fastapi\\applications.py:4495: DeprecationWarning: \n",
      "        on_event is deprecated, use lifespan event handlers instead.\n",
      "\n",
      "        Read more about it in the\n",
      "        [FastAPI docs for Lifespan Events](https://fastapi.tiangolo.com/advanced/events/).\n",
      "        \n",
      "  return self.router.on_event(event_type)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JulienRigot\\Projets\\zzEnvs\\Transport\\Lib\\site-packages\\gradio\\routes.py:1150: DeprecationWarning: \n",
      "        on_event is deprecated, use lifespan event handlers instead.\n",
      "\n",
      "        Read more about it in the\n",
      "        [FastAPI docs for Lifespan Events](https://fastapi.tiangolo.com/advanced/events/).\n",
      "        \n",
      "  @app.on_event(\"startup\")\n",
      "c:\\Users\\JulienRigot\\Projets\\zzEnvs\\Transport\\Lib\\site-packages\\fastapi\\applications.py:4495: DeprecationWarning: \n",
      "        on_event is deprecated, use lifespan event handlers instead.\n",
      "\n",
      "        Read more about it in the\n",
      "        [FastAPI docs for Lifespan Events](https://fastapi.tiangolo.com/advanced/events/).\n",
      "        \n",
      "  return self.router.on_event(event_type)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JulienRigot\\Projets\\zzEnvs\\Transport\\Lib\\site-packages\\starlette\\templating.py:178: DeprecationWarning: The `name` is not the first parameter anymore. The first parameter should be the `Request` instance.\n",
      "Replace `TemplateResponse(name, {\"request\": request})` by `TemplateResponse(request, name)`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\JulienRigot\\Projets\\zzEnvs\\Transport\\Lib\\site-packages\\starlette\\templating.py:178: DeprecationWarning: The `name` is not the first parameter anymore. The first parameter should be the `Request` instance.\n",
      "Replace `TemplateResponse(name, {\"request\": request})` by `TemplateResponse(request, name)`.\n",
      "  warnings.warn(\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\JulienRigot\\Projets\\zzEnvs\\Transport\\Lib\\site-packages\\gradio\\queueing.py\", line 532, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\JulienRigot\\Projets\\zzEnvs\\Transport\\Lib\\site-packages\\gradio\\route_utils.py\", line 276, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\JulienRigot\\Projets\\zzEnvs\\Transport\\Lib\\site-packages\\gradio\\blocks.py\", line 1928, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\JulienRigot\\Projets\\zzEnvs\\Transport\\Lib\\site-packages\\gradio\\blocks.py\", line 1514, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\JulienRigot\\Projets\\zzEnvs\\Transport\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\JulienRigot\\Projets\\zzEnvs\\Transport\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2144, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\JulienRigot\\Projets\\zzEnvs\\Transport\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 851, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\JulienRigot\\Projets\\zzEnvs\\Transport\\Lib\\site-packages\\gradio\\utils.py\", line 832, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\JulienRigot\\AppData\\Local\\Temp\\ipykernel_9372\\2289944834.py\", line 350, in make_daily_movements\n",
      "    conn.upsertVertices(\"Nodes\", nodes_batch_full)\n",
      "  File \"c:\\Users\\JulienRigot\\Projets\\zzEnvs\\Transport\\Lib\\site-packages\\pyTigerGraph\\pyTigerGraphVertex.py\", line 286, in upsertVertices\n",
      "    ret = self._post(self.restppUrl + \"/graph/\" + self.graphname, data=data)[0][\"accepted_vertices\"]\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\JulienRigot\\Projets\\zzEnvs\\Transport\\Lib\\site-packages\\pyTigerGraph\\pyTigerGraphBase.py\", line 383, in _post\n",
      "    res = self._req(\"POST\", url, authMode, headers, data, resKey, skipCheck, params, jsonData=jsonData)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\JulienRigot\\Projets\\zzEnvs\\Transport\\Lib\\site-packages\\pyTigerGraph\\pyTigerGraphBase.py\", line 295, in _req\n",
      "    res.raise_for_status()\n",
      "  File \"c:\\Users\\JulienRigot\\Projets\\zzEnvs\\Transport\\Lib\\site-packages\\requests\\models.py\", line 1021, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 408 Client Error: Timeout for url: https://d6e9eef375704c8893b47bdc6132b082.i.tgcloud.io:443/restpp/graph/VWG\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\JulienRigot\\Projets\\zzEnvs\\Transport\\Lib\\site-packages\\gradio\\queueing.py\", line 532, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\JulienRigot\\Projets\\zzEnvs\\Transport\\Lib\\site-packages\\gradio\\route_utils.py\", line 276, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\JulienRigot\\Projets\\zzEnvs\\Transport\\Lib\\site-packages\\gradio\\blocks.py\", line 1928, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\JulienRigot\\Projets\\zzEnvs\\Transport\\Lib\\site-packages\\gradio\\blocks.py\", line 1514, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\JulienRigot\\Projets\\zzEnvs\\Transport\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\JulienRigot\\Projets\\zzEnvs\\Transport\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2144, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\JulienRigot\\Projets\\zzEnvs\\Transport\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 851, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\JulienRigot\\Projets\\zzEnvs\\Transport\\Lib\\site-packages\\gradio\\utils.py\", line 832, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\JulienRigot\\AppData\\Local\\Temp\\ipykernel_9372\\2289944834.py\", line 350, in make_daily_movements\n",
      "    conn.upsertVertices(\"Nodes\", nodes_batch_full)\n",
      "  File \"c:\\Users\\JulienRigot\\Projets\\zzEnvs\\Transport\\Lib\\site-packages\\pyTigerGraph\\pyTigerGraphVertex.py\", line 286, in upsertVertices\n",
      "    ret = self._post(self.restppUrl + \"/graph/\" + self.graphname, data=data)[0][\"accepted_vertices\"]\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\JulienRigot\\Projets\\zzEnvs\\Transport\\Lib\\site-packages\\pyTigerGraph\\pyTigerGraphBase.py\", line 383, in _post\n",
      "    res = self._req(\"POST\", url, authMode, headers, data, resKey, skipCheck, params, jsonData=jsonData)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\JulienRigot\\Projets\\zzEnvs\\Transport\\Lib\\site-packages\\pyTigerGraph\\pyTigerGraphBase.py\", line 295, in _req\n",
      "    res.raise_for_status()\n",
      "  File \"c:\\Users\\JulienRigot\\Projets\\zzEnvs\\Transport\\Lib\\site-packages\\requests\\models.py\", line 1021, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 408 Client Error: Timeout for url: https://d6e9eef375704c8893b47bdc6132b082.i.tgcloud.io:443/restpp/graph/VWG\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "class GradioMetro:\n",
    "    \n",
    "    def front_func(self):\n",
    "        with gr.Blocks(css=\"stylessupersimple.css\", title =\"Red de distribución\",theme=\"Monochrome\") as demo:\n",
    "            gr.Markdown(\"## \"\"![](file/Gradio/logo_lis.svg) Red de distribución\"\"\", elem_classes=\"cabecero\")\n",
    "            with gr.Tabs() as tabs:\n",
    "\n",
    "                with gr.TabItem(\"KPIs red\",id=1):\n",
    "                    with gr.Row():\n",
    "                        with gr.Column(scale=5):\n",
    "                            map_tiger = gr.HTML(value = \"\"\" <html lang=\"en\"><head><meta charset=\"UTF-8\"><meta name=\"viewport\" content=\"width=device-width, \n",
    "                                    initial-scale=1.0\"></head><body><iframe width=\"1000\" height=\"800\"\n",
    "                                    src=\"\"\" + tigergraph_insights_map1 + \"\"\" \n",
    "                                    title=\"tigergarph insights\" frameborder=\"0\"></iframe></body></html>\"\"\")\n",
    "                            btn_reload_map =  gr.Button(\"Recargar mapa\",elem_classes=\"otherbutton\")\n",
    "                            btn_reload_map.click(fn=reset_html1_1000,outputs=[map_tiger])  \n",
    "                        with gr.Column(scale=2):\n",
    "                            gr.Number(label=\"KPI : Cantidad de Aristas\",value=numEdges,elem_classes='textbox')\n",
    "                            gr.Number(label=\"KPI : Cantidad de Nodos\",value = numNodes,elem_classes='textbox')\n",
    "                            gr.Number(label= \"KPI : Capacidad media por arista\",value = avg_capacity,elem_classes='textbox')\n",
    "                            gr.Number(label=\"KPI : Capacidad total de las aristas \",value = total_capacity_edges,elem_classes='textbox')\n",
    "                            gr.Number(label= \"KPI : Capacidad total de los Almacenes\",value = total_capacity_warehouse,elem_classes='textbox')\n",
    "                            gr.Number(label=\"KPI : Stock total de los almacenes\",value = total_stock,elem_classes='textbox')\n",
    "                \n",
    "                with gr.TabItem(\"Cargar movimientos\",id=2):\n",
    "                    with gr.Row():\n",
    "                        with gr.Column(scale=5):\n",
    "                            upload_file = gr.File(label=\"Cargar fichero\", type=\"filepath\",elem_classes='textbox')\n",
    "\n",
    "                        with gr.Column(scale=4):\n",
    "                            dropdown_column_start = gr.Dropdown(label='Columna del envio', choices = [],  interactive=True, allow_custom_value= True,elem_classes='textbox')\n",
    "                            dropdown_column_arrival = gr.Dropdown(label='Columna de la llegada', choices = [],  interactive=True, allow_custom_value= True,elem_classes='textbox')\n",
    "                            dropdown_column_quantity = gr.Dropdown(label='Columna de la cantidad', choices = [],  interactive=True, allow_custom_value= True ,elem_classes='textbox')\n",
    "                            load_data_send = gr.Button(\"Lanzar los envios\",elem_classes=\"otherbutton\")\n",
    "                            upload_file.upload(read_csv_path,inputs=[upload_file],outputs=[dropdown_column_start,dropdown_column_arrival,dropdown_column_quantity])\n",
    "                    with gr.Row():\n",
    "                        logs = gr.Textbox(label=\"Logs\",elem_classes=\"dropdown\")\n",
    "\n",
    "                    with gr.Row():\n",
    "                        with gr.Column(scale=10):\n",
    "                            map_entrega = gr.HTML(value = \"\"\" <html lang=\"en\"><head><meta charset=\"UTF-8\"><meta name=\"viewport\" content=\"width=device-width, \n",
    "                                    initial-scale=1.0\"></head><body><iframe width=\"800\" height=\"800\"\n",
    "                                    src=\"\"\" + tigergraph_insights_map + \"\"\" \n",
    "                                    title=\"tigergarph insights\" frameborder=\"0\"></iframe></body></html>\"\"\", visible = False\n",
    "                                    )\n",
    "                            btn_reload_map2 = gr.Button(\"Recargar mapa\",elem_classes=\"otherbutton\",visible=False)\n",
    "                            btn_reload_map2.click(fn=reset_html,outputs=[map_entrega])  \n",
    "                        with gr.Column(scale=6):\n",
    "                  \n",
    "                            operation_number = gr.Number(label=\"KPI : Numero de operaciones\", visible=False)\n",
    "                            palets_number = gr.Number(label=\"KPI : Numero de palets\", visible=False)\n",
    "                            origin_number = gr.Number(label=\"KPI : Numero de origen\", visible=False)\n",
    "                            distinct_destinations = gr.Number(label=\"KPI : Destinaciones diferentes\", visible=False)\n",
    "                            total_cost = gr.Number(label=\"KPI : Coste total\", visible=False)\n",
    "                            total_cost_per_palet = gr.Number(label=\"KPI : Coste por palet\", visible=False)\n",
    "        \n",
    "                        load_data_send.click(make_daily_movements,inputs=[upload_file,dropdown_column_start,dropdown_column_arrival,dropdown_column_quantity],\n",
    "                                             outputs=[logs,map_entrega,btn_reload_map2,operation_number,palets_number,origin_number,distinct_destinations,total_cost,total_cost_per_palet])\n",
    "\n",
    "                with gr.TabItem(\"Escenario What if\", id=3):\n",
    "                    with gr.Row():\n",
    "                        with gr.Column():\n",
    "                            gr.Markdown(\"# Añadir/modificar nodo\",elem_classes=\"cabecero\")\n",
    "                            new_node_id = gr.Textbox(label=\"Nombre nuevo nodo\",elem_classes=\"dropdown\")\n",
    "                            for e in attributes_nodes_list:\n",
    "                                with gr.Row():\n",
    "                                    atributes_nodes[e] = gr.Number(label=e,elem_classes=\"dropdown\")\n",
    "                        \n",
    "                            with gr.Row():\n",
    "                                btn_modif_nodes = gr.Button(\"Añadir/modificar nodos\",elem_classes=\"otherbutton\")\n",
    "\n",
    "                        with gr.Column():\n",
    "                            gr.Markdown(\"# Añadir/modificar arista\",elem_classes=\"cabecero\")\n",
    "\n",
    "                            source_vertex_id_edge = gr.Textbox(label=\"Nodo de origen\",elem_classes=\"dropdown\",elem_id = \"source_vertex\")\n",
    "                            target_vertex_id_edge = gr.Textbox(label=\"Nodo de destino\",elem_classes=\"dropdown\")\n",
    "\n",
    "                            for e in attributes_edges_list:\n",
    "                                with gr.Row():\n",
    "                                    atributes_edges[e] = gr.Number(label=e,elem_classes=\"dropdown\")\n",
    "                            btn_modif_edge = gr.Button(\"Añadir/modificar arista\",elem_classes=\"otherbutton\")\n",
    "\n",
    "                        with gr.Column():\n",
    "                            gr.Markdown(\"# Borrar nodo/arista\",elem_classes=\"cabecero\")\n",
    "                            source_vertex_id = gr.Textbox(label=\"Nodo de origen\",elem_classes=\"dropdown\",container = True)\n",
    "                            target_vertex_id = gr.Textbox(label=\"Nodo de destino (si es una arista)\",elem_classes=\"dropdown\",container = True)\n",
    "                            btn_erase_node = gr.Button(\"Borrar nodo\",elem_classes=\"otherbutton\")\n",
    "                            btn_erase_edge = gr.Button(\"Borrar arista\",elem_classes=\"otherbutton\")  \n",
    "\n",
    "                    with gr.Row():\n",
    "                        logs = gr.Textbox(label = \"logs\",elem_classes=\"dropdown\")\n",
    "\n",
    "                    with gr.Row():\n",
    "                        with gr.Column(scale=5):\n",
    "                            upload_file = gr.File(label=\"Cargar fichero\", type=\"filepath\",elem_classes='textbox')\n",
    "                        with gr.Column(scale=4):\n",
    "                            dropdown_column_start = gr.Dropdown(label='Columna del envio', choices = [],  interactive=True, allow_custom_value= True, elem_classes=\"dropdown\")\n",
    "                            dropdown_column_arrival = gr.Dropdown(label='Columna de la llegada', choices = [],  interactive=True, allow_custom_value= True, elem_classes=\"dropdown\")\n",
    "                            dropdown_column_quantity = gr.Dropdown(label='Columna de la cantidad', choices = [],  interactive=True, allow_custom_value= True, elem_classes=\"dropdown\")\n",
    "                            load_data_send1 = gr.Button(\"Lanzar los envios en la red modificada\",elem_classes=\"otherbutton\")\n",
    "                            upload_file.upload(read_csv_path,inputs=[upload_file],outputs=[dropdown_column_start,dropdown_column_arrival,dropdown_column_quantity])\n",
    "\n",
    "                    with gr.Row():\n",
    "                        logs1 = gr.Textbox(label = \"logs\",elem_classes=\"dropdown\")\n",
    "\n",
    "                            \n",
    "                    with gr.Row():\n",
    "                        with gr.Column():\n",
    "                            markdown1 = gr.Markdown(\"# KPIs red original\",visible=False,elem_classes = \"cabecero\")\n",
    "                            num_edges_number1 = gr.Number(label=\"KPI : Cantidad de Aristas\",value=numEdges,visible=False)\n",
    "                            num_nodes_number1 = gr.Number(label=\"KPI : Cantidad de Nodos\",value = numNodes,visible=False)\n",
    "                            capacity_average_number1 = gr.Number(label= \"KPI : Capacidad media por arista\",value = avg_capacity,visible=False)\n",
    "                            total_capacity_edge_number1 = gr.Number(label=\"KPI : Capacidad total de las aristas \",value = total_capacity_edges,visible=False)\n",
    "                            total_capacity_warehouse_number1 = gr.Number(label= \"KPI : Capacidad total de los Almacenes\",value = total_capacity_warehouse,visible=False)\n",
    "                            total_stock_number1 = gr.Number(label=\"KPI : Stock total de los almacenes\",value = total_stock,visible=False)\n",
    "                            ####KPI ENTREGA RED ORGINAL####\n",
    "                        with gr.Column():\n",
    "                            markdown2 = gr.Markdown(\"# KPIs Entrega original\",visible=False,elem_classes = \"cabecero\")\n",
    "                            operation_number1 = gr.Number(label= \"KPI : Numero de operaciones\",visible=False)\n",
    "                            palets_number1 = gr.Number(label= \"KPI : Numero de palets\",visible=False)\n",
    "                            origin_number1 = gr.Number(label= \"KPI : Numero de origen\",visible=False)\n",
    "                            distinct_destinations1 = gr.Number(label= \"KPI : Destinaciones diferentes\",visible=False)\n",
    "                            total_cost1 = gr.Number(label= \"KPI : Coste total\",visible=False)\n",
    "                            total_cost_per_palet1 = gr.Number(label= \"KPI : Coste por palet\",visible=False)\n",
    "                        with gr.Column():\n",
    "                            ###KPI RED MODIFICADA####\n",
    "                            markdown1_simul =gr.Markdown(\"# KPIs red modificada\",visible=False,elem_classes = \"cabecero\")\n",
    "                            num_edges_number_simul = gr.Number(label=\"KPI : Cantidad de Aristas\",value=\"numEdges1\",visible=False)\n",
    "                            num_nodes_number_simul = gr.Number(label=\"KPI : Cantidad de Nodos\",value = \"numNodes1\",visible=False)\n",
    "                            capacity_average_number_simul = gr.Number(label= \"KPI : Capacidad media por arista\",value = \"avg_capacity1\",visible=False)\n",
    "                            total_capacity_edge_number_simul = gr.Number(label=\"KPI : Capacidad total de las aristas \",value = \"total_capacity_edges1\",visible=False)\n",
    "                            total_capacity_warehouse_number_simul = gr.Number(label= \"KPI : Capacidad total de los Almacenes\",value = \"total_capacity_warehouse1\",visible=False)\n",
    "                            total_stock_number_simul = gr.Number(label=\"KPI : Stock total de los almacenes\",value = \"total_stock1\",visible=False)\n",
    "                        with gr.Column():\n",
    "                            markdown2_simul =gr.Markdown(\"# KPIs entrega red modificada\",visible=False,elem_classes = \"cabecero\")\n",
    "                            operation_number_simul = gr.Number(label= \"KPI : Numero de operaciones\",visible=False)\n",
    "                            palets_number_simul = gr.Number(label= \"KPI : Numero de palets\",visible=False)\n",
    "                            origin_number_simul = gr.Number(label= \"KPI : Numero de origen\",visible=False)\n",
    "                            distinct_destinations_simul = gr.Number(label= \"KPI : Destinaciones diferentes\",visible=False)\n",
    "                            total_cost_simul = gr.Number(label= \"KPI : Coste total\",visible=False)\n",
    "                            total_cost_per_palet_simul = gr.Number(label= \"KPI : Coste por palet\",visible=False)\n",
    "                    \n",
    "                    with gr.Row():\n",
    "                        diference_price = gr.Number(label=\" porcentaje diferencia precio\",value = avg_capacity,visible=False)\n",
    "\n",
    "\n",
    "\n",
    "                    with gr.Row():\n",
    "                        with gr.Column():\n",
    "                            markdown_mapa_original =gr.Markdown(\"# Mapa red original\",visible=False,elem_classes = \"cabecero\")\n",
    "                            map_entrega_original = gr.HTML(value = \"\"\" <html lang=\"en\"><head><meta charset=\"UTF-8\"><meta name=\"viewport\" content=\"width=device-width, \n",
    "                                        initial-scale=1.0\"></head><body><iframe width=\"800\" height=\"800\"\n",
    "                                        src=\"\"\" + tigergraph_insights_map + \"\"\" \n",
    "                                        title=\"tigergarph insights\" frameborder=\"0\"></iframe></body></html>\"\"\",visible=False)\n",
    "                            btn_reload_map_original = gr.Button(\"Recargar mapa\",visible=False)\n",
    "\n",
    "                        with gr.Column():\n",
    "                            markdown_mapa_modificada =gr.Markdown(\"# Mapa modificada\",visible=False,elem_classes = \"cabecero\")\n",
    "                            map_entrega_simulacion = gr.HTML(value = \"\"\" <html lang=\"en\"><head><meta charset=\"UTF-8\"><meta name=\"viewport\" content=\"width=device-width, \n",
    "                                        initial-scale=1.0\"></head><body><iframe width=\"800\" height=\"800\"\n",
    "                                        src=\"\"\" + tigergraph_insights_map1 + \"\"\" \n",
    "                                        title=\"tigergarph insights\" frameborder=\"0\"></iframe></body></html>\"\"\",visible=False)\n",
    "                            btn_reload_map_simul = gr.Button(\"Recargar mapa\",visible=False)\n",
    "                    \n",
    "                    with gr.Row():\n",
    "                        valor_porcentaje = gr.Number(label=\"Porcentaje de subir/bajar la carga\",visible=False)\n",
    "                        \n",
    "                    with gr.Row():\n",
    "                        btn_subir_carga = gr.Button(\"Subir carga\",elem_classes=\"otherbutton\",visible=False)\n",
    "                        btn_bajar_carga = gr.Button(\"Bajar carga\",elem_classes=\"otherbutton\",visible=False)\n",
    "\n",
    "                    with gr.Row():\n",
    "                        with gr.Column(scale=5):\n",
    "                            logs_red_state_o = gr.Textbox(label=\"Estado de la red\", visible=False,elem_classes=\"dropdown\")\n",
    "\n",
    "                            KPIo_node_sobrecargado = gr.Textbox(label=\"Nodos sobrecargados\", visible=False,elem_classes=\"dropdown\")\n",
    "                            KPIo_node_subcargado = gr.Textbox(label=\"Nodos subcargados\", visible=False,elem_classes=\"dropdown\")\n",
    "                            KPIo_arista_sobrecargada = gr.Textbox(label=\"Aristas sobrecargadas\", visible=False,elem_classes=\"dropdown\")\n",
    "                            KPIo_arista_subcargada = gr.Textbox(label=\"Aristas subcargadas\", visible=False,elem_classes=\"dropdown\")\n",
    "                        with gr.Column(scale=5):\n",
    "                            logs_red_state_m = gr.Textbox(label=\"Estado de la red\", visible=False,elem_classes=\"dropdown\")\n",
    "                            KPIm_node_sobrecargado = gr.Textbox(label=\"Nodos sobrecargados\", visible=False,elem_classes=\"dropdown\")\n",
    "                            KPIm_node_subcargado = gr.Textbox(label=\"Nodos subcargados\", visible=False,elem_classes=\"dropdown\")\n",
    "                            KPIm_arista_sobrecargada = gr.Textbox(label=\"Aristas sobrecargadas\", visible=False,elem_classes=\"dropdown\")\n",
    "                            KPIm_arista_subcargada = gr.Textbox(label=\"Aristas subcargadas\", visible=False,elem_classes=\"dropdown\")\n",
    "\n",
    "\n",
    "                        load_data_send1.click(make_daily_movements1,inputs=[upload_file,dropdown_column_start,dropdown_column_arrival,dropdown_column_quantity],\n",
    "                                            outputs=[logs1,markdown_mapa_original,map_entrega_original,btn_reload_map_original,markdown_mapa_modificada,map_entrega_simulacion,btn_reload_map_simul,\n",
    "                                                    markdown1,num_edges_number1,num_nodes_number1,capacity_average_number1,total_capacity_edge_number1,total_capacity_warehouse_number1,total_stock_number1,   #Red original\n",
    "                                                    markdown2,operation_number1,palets_number1,origin_number1,distinct_destinations1,total_cost1,total_cost_per_palet1,   #Entrega original\n",
    "                                                    markdown1_simul,num_edges_number_simul,num_nodes_number_simul,capacity_average_number_simul,total_capacity_edge_number_simul,total_capacity_warehouse_number_simul,total_stock_number_simul, #Red simulada\n",
    "                                                    markdown2_simul,operation_number_simul,palets_number_simul,origin_number_simul,distinct_destinations_simul,total_cost_simul,total_cost_per_palet_simul #Entrega simulada \n",
    "                                                    ,logs_red_state_o,\n",
    "                                                    KPIo_node_sobrecargado,KPIo_node_subcargado,KPIo_arista_sobrecargada,KPIo_arista_subcargada,\n",
    "                                                    logs_red_state_m,\n",
    "                                                    KPIm_node_sobrecargado,KPIm_node_subcargado,KPIm_arista_sobrecargada,KPIm_arista_subcargada,diference_price,\n",
    "                                                    valor_porcentaje,btn_subir_carga,btn_bajar_carga],\n",
    "                                                    scroll_to_output=True) \n",
    "                        \n",
    "                        btn_subir_carga.click(make_daily_movements_with_percentages_positive,inputs=[upload_file,dropdown_column_start,dropdown_column_arrival,dropdown_column_quantity,valor_porcentaje],\n",
    "                                              outputs=[map_entrega_simulacion,logs_red_state_m,KPIm_node_sobrecargado,KPIm_node_subcargado,KPIm_arista_sobrecargada,KPIm_arista_subcargada])\n",
    "                        btn_bajar_carga.click(make_daily_movements_with_percentages_negative,inputs=[upload_file,dropdown_column_start,dropdown_column_arrival,dropdown_column_quantity,valor_porcentaje],\n",
    "                                              outputs=[map_entrega_simulacion,logs_red_state_m,KPIm_node_sobrecargado,KPIm_node_subcargado,KPIm_arista_sobrecargada,KPIm_arista_subcargada])\n",
    "\n",
    "\n",
    "                    inputs_edge = [source_vertex_id_edge,target_vertex_id_edge] + [atributes_edges[e] for e in attributes_edges_list]\n",
    "                    \n",
    "                    inputs_nodes = [new_node_id] + [atributes_nodes[e] for e in attributes_nodes_list]\n",
    "                    \n",
    "                    def add_edge_with_values_wrapper(source, target, *args):\n",
    "                        attributes = {e: arg for e, arg in zip(attributes_edges_list, args)}\n",
    "                        return add_edge_with_values(source, target, attributes)\n",
    "\n",
    "                    btn_modif_nodes.click(fn=add_node_with_values, inputs=inputs_nodes, outputs=[logs,map_entrega_simulacion])\n",
    "                    btn_modif_edge.click(fn=add_edge_with_values_wrapper, inputs=inputs_edge, outputs=[logs,map_entrega_simulacion])\n",
    "                    btn_erase_node.click(fn=erase_node, inputs=[source_vertex_id], outputs=[logs,map_entrega_simulacion])\n",
    "                    btn_erase_edge.click(fn=erase_edge, inputs=[source_vertex_id,target_vertex_id], outputs=[logs,map_entrega_simulacion])\n",
    "                    btn_reload_map_original.click(fn=reset_html_800,outputs=[map_entrega_original])\n",
    "                    btn_reload_map_simul.click(fn=reset_html1_800,outputs=[map_entrega_simulacion])\n",
    "\n",
    "                demo.launch(max_threads=1000)\n",
    "                \n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    lis = GradioMetro()\n",
    "    lis.front_func()\n",
    "\n",
    "\n",
    "    #Reactualizar los colores cuando se hace modif de arrista despues de la entrega"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
