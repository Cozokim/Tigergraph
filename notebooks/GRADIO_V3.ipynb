{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "secret token: uf9a4lta7oufn1ib110t49c4ig43pqe7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JulienRigot\\Projets\\zzEnvs\\Transport\\Lib\\site-packages\\pyTigerGraph\\pyTigerGraphBase.py:105: DeprecationWarning: The `apiToken` parameter is deprecated; use `getToken()` function instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pyTigerGraph as tg\n",
    "import pandas as pd\n",
    "import gradio as gr\n",
    "hostName = \"https://4da1bd47ec034979919364bf0615f5f4.i.tgcloud.io\"\n",
    "graphName = \"VWG\"\n",
    "secret = \"uoabr03s0ls2prn9hpdupch6vquvn6gu\"\n",
    "userName = \"user_1\"\n",
    "password = \"A1z2e3r4*\"\n",
    "tigergraph_insights_map = \"https://tools.tgcloud.io/insights/app/67eZLiuqbdk5nNg9QxWQfA/page/gvxC91DiSnRKvPvWzfR9iH/widgetShare/sQFKgLZh8iCgVFrarvUVTr?domain=4da1bd47ec034979919364bf0615f5f4.i&orgName=lis-gordias&clusterid=5fc3b84f-33fb-41b4-b856-2e983aa290f6&TigerGraphToken=3ff2a285-25b4-4a77-98c2-80bfbde3fd73\"\n",
    "graph = tg.TigerGraphConnection(host=hostName, graphname=graphName)\n",
    "\n",
    "authToken = graph.getToken(secret)\n",
    "authToken = authToken[0]\n",
    "print(f\"secret token: {authToken}\")\n",
    "conn = tg.TigerGraphConnection(host=hostName, graphname=graphName, username=userName, password=password, apiToken=authToken)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tab 0 (cargar datos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import threading\n",
    "import networkx as nx\n",
    "\n",
    "# Helper functions\n",
    "def path_taken(results):\n",
    "    edges = results[2]['@@display_edge_set']\n",
    "    node_initial = None\n",
    "    edge_to_ids = {edge['to_id'] for edge in edges}\n",
    "    for edge in edges:\n",
    "        if edge['from_id'] not in edge_to_ids:\n",
    "            node_initial = edge['from_id']\n",
    "            break\n",
    "    if node_initial is None:\n",
    "        raise ValueError(\"initial node cannot be determined.\")\n",
    "    current_node = node_initial\n",
    "    path = [current_node]\n",
    "    while True:\n",
    "        next_node = None\n",
    "        for edge in edges:\n",
    "            if edge['from_id'] == current_node:\n",
    "                next_node = edge['to_id']\n",
    "                break\n",
    "        if next_node is None:\n",
    "            break\n",
    "        path.append(next_node)\n",
    "        current_node = next_node\n",
    "    nodes = {node_name: node_name for node_name in path}\n",
    "    ordered_nodes = [nodes[node_name] for node_name in path]\n",
    "    return ordered_nodes\n",
    "\n",
    "def add_or_update_final_nodes_batch(nodes_batch_full, nodes_batch , charge):\n",
    "    existing_cities = [city for city, _ in nodes_batch_full]\n",
    "    for node, _ in nodes_batch:\n",
    "        if node in existing_cities:\n",
    "            # search if town already in nodes_batch_full\n",
    "            for i, (city, stock) in enumerate(nodes_batch_full):\n",
    "                if city == node:\n",
    "                    # update stock\n",
    "                    if i == 0:\n",
    "                        nodes_batch_full[i] = (city, {\"Stock\": nodes_batch_full[i][1][\"Stock\"] - charge})\n",
    "                    else:\n",
    "                        nodes_batch_full[i] = (city, {\"Stock\": nodes_batch_full[i][1][\"Stock\"] + charge})\n",
    "            continue\n",
    "        else:\n",
    "            # add new entries to nodes_batch_full\n",
    "            nodes_batch_full.extend([\n",
    "                (nodes_batch[0][0], {\"Stock\": nodes_batch[0][1][\"Stock\"]}),\n",
    "                (nodes_batch[1][0], {\"Stock\": nodes_batch[1][1][\"Stock\"]})\n",
    "            ])\n",
    "            return nodes_batch_full\n",
    "    return nodes_batch_full\n",
    "\n",
    "def add_or_update_final_edges_batch(edges_batch_full, edges_batch, charge):\n",
    "    existing_edges = [(edge[0], edge[1]) for edge in edges_batch_full]\n",
    "    \n",
    "    for edge in edges_batch:\n",
    "        # edge already exist ? \n",
    "        if (edge[0], edge[1]) in existing_edges or (edge[1], edge[0]) in existing_edges:\n",
    "            # if yes, search if edge already in edges_batch_full\n",
    "            for i, (origin, destination, movement) in enumerate(edges_batch_full):\n",
    "                if (origin, destination) == (edge[0], edge[1]) or (origin, destination) == (edge[1], edge[0]):\n",
    "                    # Update\n",
    "                    edges_batch_full[i] = (origin, destination, {\"Daily_movement\": edges_batch_full[i][2][\"Daily_movement\"] + charge})\n",
    "            continue\n",
    "        else:\n",
    "            # If no, add new entries to edges_batch_full\n",
    "            edges_batch_full.append((edge[0], edge[1], {\"Daily_movement\": edge[2][\"Daily_movement\"]}))\n",
    "    \n",
    "    return edges_batch_full\n",
    "\n",
    "# Main transfer function\n",
    "def transfert_nodes_and_edges(node_initial, node_final, charge, weight_attribute=\"Capacity\", nodetype=\"Nodes\", edgetype=\"distribute_to\"):\n",
    "    global operation_count, palets_number, palets_cost, unique_origin_nodes, unique_destination_nodes, log_list, nodes_batch_full\n",
    "    results_astar = conn.runInstalledQuery(\"tg_astar_test\", params={\n",
    "        \"source_vertex\": node_final, \"source_vertex.type\": nodetype,\n",
    "        \"target_vertex\": node_initial, \"target_vertex.type\": nodetype,\n",
    "        \"e_type_set\": edgetype, \"weight_type\": \"FLOAT\",\n",
    "        \"latitude\": \"latitude\", \"longitude\": \"longitude\",\n",
    "        \"weight_attribute\": weight_attribute,\n",
    "        \"print_stats\": \"True\"\n",
    "    })\n",
    "\n",
    "    results_allpaths = conn.allPaths([(\"Nodes\", node_initial)], [(\"Nodes\", node_final)],maxLength=len(results_astar[2][\"@@display_edge_set\"])+1)\n",
    "\n",
    "\n",
    "    G = nx.Graph()\n",
    "\n",
    "    # add nodes\n",
    "    for vertex in results_allpaths[0]['vertices']:\n",
    "        G.add_node(vertex['v_id'], **vertex['attributes'])\n",
    "\n",
    "    # add edges and attributes \n",
    "    for edge in results_allpaths[0]['edges']:\n",
    "        G.add_edge(edge['from_id'], edge['to_id'], **edge['attributes'])\n",
    "\n",
    "    \n",
    "    def find_two_lowest_price_paths(G, node_initial, node_final, edge_len):\n",
    "            \n",
    "        all_paths = nx.all_simple_paths(G, node_initial, node_final)\n",
    "\n",
    "        def calculate_total_price(G, path):\n",
    "            total_price = 0\n",
    "            for i in range(len(path) - 1):\n",
    "                edge_data = G[path[i]][path[i + 1]]\n",
    "                total_price += edge_data['Price']\n",
    "            return total_price\n",
    "        \n",
    "        max_path_length = len(edge_len) + 2\n",
    "\n",
    "        path_prices = []\n",
    "\n",
    "        for path in all_paths:\n",
    "            if len(path) <= max_path_length:\n",
    "                total_price = calculate_total_price(G, path)\n",
    "                path_prices.append((path, total_price))\n",
    "\n",
    "        path_prices.sort(key=lambda x: x[1])\n",
    "\n",
    "        top_two_paths = path_prices[:2]\n",
    "\n",
    "        proposed_paths = []\n",
    "    \n",
    "        for path, total_price in top_two_paths:\n",
    "            nodes_info = []\n",
    "            edges_info = []\n",
    "\n",
    "            for i in range(len(path) - 1):\n",
    "                from_node_id = path[i]\n",
    "                to_node_id = path[i + 1]\n",
    "                edge_data = G[from_node_id][to_node_id]\n",
    "                price = edge_data['Price']\n",
    "                edges_info.append({'e_type': 'distribute_to', 'from_id': from_node_id, 'from_type': 'Nodes',\n",
    "                                'to_id': to_node_id, 'to_type': 'Nodes', 'directed': False,\n",
    "                                'attributes': {'Capacity': edge_data['Capacity'], 'Price': price,\n",
    "                                                'Daily_movement': edge_data['Daily_movement']}})\n",
    "                from_node_attributes = G.nodes[from_node_id]\n",
    "                nodes_info.append({'v_id': from_node_id, 'v_type': 'Nodes', 'attributes': from_node_attributes})\n",
    "\n",
    "            proposed_paths.append({'vertices': nodes_info, 'edges': edges_info, 'total_price': total_price})\n",
    "\n",
    "        return proposed_paths\n",
    "    \n",
    "    top_alternative_paths_and_prices = find_two_lowest_price_paths(G, node_initial, node_final, results_astar[2][\"@@display_edge_set\"])\n",
    "\n",
    "\n",
    "    order_taken = path_taken(results_astar)\n",
    "    edge_set = results_astar[2]['@@display_edge_set']\n",
    "    reordered_edges_set = []\n",
    "    for location in order_taken:\n",
    "        for edge in edge_set:\n",
    "            if edge['from_id'] == location:\n",
    "                reordered_edges_set.append(edge)\n",
    "\n",
    "    node_set = results_astar[2]['tmp']\n",
    "    reordered_nodes_set = []\n",
    "    for location in order_taken:\n",
    "        for item in node_set:\n",
    "            if item['v_id'] == location:\n",
    "                reordered_nodes_set.append(item)\n",
    "\n",
    "    try:\n",
    "        node_i_stock = reordered_nodes_set[0][\"attributes\"][\"Stock\"]\n",
    "        node_f_stock = reordered_nodes_set[-1][\"attributes\"][\"Stock\"]\n",
    "        node_i_unload_capacity = reordered_nodes_set[0][\"attributes\"][\"UnloadCapacity\"]\n",
    "        node_f_load_capacity = reordered_nodes_set[-1][\"attributes\"][\"LoadCapacity\"]\n",
    "\n",
    "        if charge > node_i_stock:\n",
    "            error_message = f\"{node_initial} to {node_final}: Not enough stock ({charge} > {node_i_stock})\"\n",
    "            log_list.append(error_message)\n",
    "\n",
    "        if charge > node_f_load_capacity:\n",
    "            error_message = f\"{node_initial} to {node_final}: Not enough load capacity from receiving warehouse (charge: {charge} > LoadCapacity: {node_f_load_capacity})\"\n",
    "            log_list.append(error_message)\n",
    "\n",
    "        if charge > node_i_unload_capacity:\n",
    "            error_message = f\"{node_initial} to {node_final}: Not enough unload capacity from starting warehouse (charge: {charge} > UnloadCapacity: {node_i_unload_capacity})\"\n",
    "            log_list.append(error_message)\n",
    "\n",
    "        capacity_edge = reordered_edges_set[0][\"attributes\"][\"Capacity\"]\n",
    "        daily_movement = reordered_edges_set[0][\"attributes\"][\"Daily_movement\"]\n",
    "\n",
    "        if daily_movement + charge > capacity_edge:\n",
    "            error_message = f\"Send {capacity_edge} palets from {node_initial} to {node_final}: Not enough edge capacity ({daily_movement + charge} > {capacity_edge})\"\n",
    "            log_list.append(error_message)\n",
    "\n",
    "        nodes_batch = [\n",
    "            (node_initial, {\"Stock\": node_i_stock - charge}),\n",
    "            (node_final, {\"Stock\": node_f_stock + charge})\n",
    "        ]\n",
    "\n",
    "        edges_batch = []\n",
    "        for element in reordered_edges_set:\n",
    "            element['attributes']['Daily_movement'] += charge\n",
    "            edges_batch.append((element[\"from_id\"], element[\"to_id\"], {\"Daily_movement\": element[\"attributes\"][\"Daily_movement\"]}))\n",
    "            palets_cost += element[\"attributes\"][\"Price\"]\n",
    "\n",
    "        unique_origin_nodes.add(node_initial)\n",
    "        unique_destination_nodes.add(node_final)\n",
    "        operation_count += 1\n",
    "        palets_number += charge\n",
    "\n",
    "        return nodes_batch , edges_batch , top_alternative_paths_and_prices\n",
    "\n",
    "    except Exception as e:\n",
    "        error_message = f\"Error in the transfer: {e}\"\n",
    "        log_list.append(error_message)\n",
    "        return error_message\n",
    "\n",
    "# Thread safety\n",
    "lock = threading.Lock()\n",
    "\n",
    "def make_daily_movements(input_file, column_origin, column_destination, column_transfert):\n",
    "    global operation_count, palets_number, palets_cost, unique_origin_nodes, unique_destination_nodes, log_list, nodes_batch_full,alternatives_paths\n",
    "    operation_count = 0\n",
    "    palets_number = 0\n",
    "    palets_cost = 0\n",
    "    unique_origin_nodes = set()\n",
    "    unique_destination_nodes = set()\n",
    "    log_list = []\n",
    "    nodes_batch_full = []\n",
    "    edges_batch_full = []\n",
    "    alternatives_paths = []\n",
    "\n",
    "    df = pd.read_csv(input_file)\n",
    "\n",
    "    def perform_transfer(row):\n",
    "        try:\n",
    "            origin = str(row[column_origin])\n",
    "            destination = str(row[column_destination])\n",
    "            volume = float(row[column_transfert])\n",
    "            nodes_batch, edges_batch, top_alternative_paths_and_prices = transfert_nodes_and_edges(origin, destination, volume)\n",
    "            with lock:\n",
    "                add_or_update_final_nodes_batch(nodes_batch_full, nodes_batch, volume)\n",
    "                add_or_update_final_edges_batch(edges_batch_full, edges_batch, volume)\n",
    "                \n",
    "                alternatives_paths.append(top_alternative_paths_and_prices)\n",
    "        except Exception as e:\n",
    "            log_list.append(f\"{origin} to {destination}, no possible path exists.\")\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=1000) as executor:\n",
    "        futures = [executor.submit(perform_transfer, row) for index, row in df.iterrows()]\n",
    "        for future in as_completed(futures):\n",
    "            pass\n",
    "\n",
    "    conn.upsertVertices(\"Nodes\", nodes_batch_full)\n",
    "    nodetype = \"Nodes\"\n",
    "    edgetype = \"distribute_to\"\n",
    "\n",
    "    conn.upsertEdges(sourceVertexType=nodetype, targetVertexType=nodetype, edgeType=edgetype, edges=edges_batch_full)\n",
    "\n",
    "    return log_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function tab 1 BIS (KPI daily movement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def operation_number():\n",
    "    return operation_count\n",
    "\n",
    "def number_palets():\n",
    "    return palets_number\n",
    "\n",
    "def origin_number():\n",
    "    global unique_origin_nodes\n",
    "    return len(unique_origin_nodes)\n",
    "\n",
    "def distinct_destinations():\n",
    "    global unique_destination_nodes\n",
    "    return len(unique_destination_nodes)\n",
    "\n",
    "def total_cost():\n",
    "    return palets_cost\n",
    "\n",
    "def cost_per_palet():\n",
    "    return palets_cost/palets_number\n",
    "\n",
    "def get_KPIs_movements():\n",
    "    return operation_number(), number_palets(), origin_number(), distinct_destinations(), total_cost(), cost_per_palet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alternative_path_1():\n",
    "    path = []\n",
    "    for edge in alternatives_paths[0][0]['edges']:\n",
    "        path.append(edge['from_id'])\n",
    "    path.append(alternatives_paths[0][0]['edges'][-1]['to_id'])\n",
    "\n",
    "    return path\n",
    "\n",
    "def alternative_price_1():\n",
    "    return alternatives_paths[0][0][\"total_price\"]\n",
    "\n",
    "def alternative_path_2():\n",
    "    path = []\n",
    "    for edge in alternatives_paths[0][1]['edges']:\n",
    "        path.append(edge['from_id'])\n",
    "    path.append(alternatives_paths[0][1]['edges'][-1]['to_id'])\n",
    "\n",
    "def alternative_price_2():\n",
    "    return alternatives_paths[0][1][\"total_price\"]\n",
    "\n",
    "def get_KPIs_alternatives():\n",
    "    return alternative_path_1(), alternative_price_1(), alternative_path_2(), alternative_price_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions tab 1 ( KPI )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edges(name_edge = \"distribute_to\"):\n",
    "    numEdges = conn.getEdgeCount(name_edge)\n",
    "    return numEdges\n",
    "\n",
    "def get_nodes(name_node = \"Nodes\"):\n",
    "    numNodes = conn.getVertexCount(name_node)\n",
    "    return numNodes\n",
    "\n",
    "def get_average_cost_per_edge(name_edge = \"distribute_to\"):\n",
    "    edge = conn.getEdgeStats(name_edge)\n",
    "    avg_capacity = edge[name_edge]['Capacity']['AVG']\n",
    "    return avg_capacity\n",
    "\n",
    "def get_total_capacity_edges(name_edge = \"distribute_to\"):\n",
    "    edge = conn.getEdgesByType(name_edge)\n",
    "    total_capacity_edges = 0\n",
    "    for warehouse in edge :\n",
    "        capacity = warehouse[\"attributes\"][\"Capacity\"]     \n",
    "        total_capacity_edges += capacity\n",
    "    return total_capacity_edges\n",
    "\n",
    "def get_total_capacity_warehouse(name_node = \"Nodes\"):\n",
    "    almacen = conn.getVertices(name_node)\n",
    "    total_capacity_warehouse = 0\n",
    "    for warehouse in almacen :\n",
    "        capacity = warehouse[\"attributes\"][\"Capacity\"]      #REPLACE CAPACITY / CARGA REAL \n",
    "        total_capacity_warehouse += capacity\n",
    "    return total_capacity_warehouse\n",
    "\n",
    "\n",
    "def get_total_stock(node = \"Nodes\"):\n",
    "    almacen = conn.getVertices(node)\n",
    "    total_stock = 0\n",
    "    for warehouse in almacen :\n",
    "        stock = warehouse[\"attributes\"][\"Stock\"]     \n",
    "        total_stock += stock\n",
    "    return total_stock\n",
    "\n",
    "\n",
    "def get_average_capacity_nodes(edge = \"distribute_to\"):\n",
    "    return get_total_capacity_warehouse()/conn.getEdgeCount(edge)\n",
    "\n",
    "def get_KPIs_network():\n",
    "    edges = get_edges()\n",
    "    nodes = get_nodes()\n",
    "    average_cost_edge = get_average_cost_per_edge()\n",
    "    total_capacity_edge = get_total_capacity_edges()\n",
    "    warehouse_total_capacity = get_total_capacity_warehouse()\n",
    "    warehouse_total_stock = get_total_stock()\n",
    "    return edges, nodes, average_cost_edge,total_capacity_edge,warehouse_total_capacity, warehouse_total_stock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions tab 2 (modif red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conn.upsertEdge(sourceVertexType=\"Nodes\",targetVertexType=\"Nodes\",edgeType=\"distribute_to\",sourceVertexId=\"Almacen 260\",targetVertexId=\"Almacen 730\",attributes={\"Capacity\" : 1000})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "global logs_modif_network\n",
    "logs_modif_network = \" \"\n",
    "\n",
    "\n",
    "# ADD NODES \n",
    "\n",
    "def add_node(id, attributes_dict=None, vertex_type=\"Nodes\"):\n",
    "    global logs_modif_network\n",
    "    if attributes_dict is None:\n",
    "        conn.upsertVertex(vertex_type, id)\n",
    "        message =  f\"Node {id} added\"\n",
    "        logs_modif_network +=message\n",
    "        return logs_modif_network\n",
    "    else:\n",
    "        attributes = json.loads(attributes_dict)\n",
    "        conn.upsertVertex(vertex_type, id, attributes=attributes)\n",
    "        message =  f\"Node {id} added with attributes {attributes} \\n\"\n",
    "        logs_modif_network +=message\n",
    "    return logs_modif_network\n",
    "\n",
    "def get_values_nodes(*args):\n",
    "    values = {key: val for key, val in zip(atributes_nodes.keys(), args)}\n",
    "    return values\n",
    "\n",
    "def get_values_edges(*args):\n",
    "    values = {key: val for key, val in zip(atributes_edges.keys(), args)}\n",
    "    return values\n",
    "\n",
    "\n",
    "def add_node_with_values(id, *args):\n",
    "    attributes = get_values_nodes(*args)\n",
    "    attributes_json = json.dumps(attributes)\n",
    "    return add_node(id, attributes_json)\n",
    "\n",
    "\n",
    "\n",
    "# ADD EDGES \n",
    "def add_new_edge(source_vertex_id, target_vertex_id, attributes_dict=None,source_vertex_type=\"Nodes\",target_vertex_type = \"Nodes\", edge_type=\"distribute_to\"):\n",
    "    global logs_modif_network\n",
    "    if attributes_dict is None:\n",
    "        conn.upsertEdge(source_vertex_type, source_vertex_id, edge_type, target_vertex_type, target_vertex_id)\n",
    "        message =  f\"Edge from {source_vertex_type}:{source_vertex_id} to {target_vertex_type}:{target_vertex_id} of type {edge_type} added\"\n",
    "        logs_modif_network += message\n",
    "        return logs_modif_network\n",
    "    else:\n",
    "        attributes = json.loads(attributes_dict)\n",
    "        conn.upsertEdge(source_vertex_type, source_vertex_id, edge_type, target_vertex_type, target_vertex_id, attributes=attributes)\n",
    "        message =  f\"Edge from {source_vertex_type}:{source_vertex_id} to {target_vertex_type}:{target_vertex_id} of type {edge_type} added with attributes {attributes} \\n\"\n",
    "        logs_modif_network += message\n",
    "    return logs_modif_network\n",
    "\n",
    "def add_edge_with_values(source_vertex_id, target_vertex_id, *args):\n",
    "    attributes = get_values_edges(*args)\n",
    "    attributes_json = json.dumps(attributes)\n",
    "    return add_new_edge(source_vertex_id,target_vertex_id, attributes_json)\n",
    "\n",
    "\n",
    "# GET ATTRIBUTES\n",
    "attributes_nodes_list = []\n",
    "attributes_edges_list = []\n",
    "conex_nodes_list = conn.getVertexAttrs('Nodes')\n",
    "conex_edges_list = conn.getEdgeAttrs('distribute_to')\n",
    "\n",
    "for node in conex_nodes_list:\n",
    "    attributes_nodes_list.append(node[0])\n",
    "\n",
    "for edge in conex_edges_list:\n",
    "    attributes_edges_list.append(edge[0])\n",
    "\n",
    "\n",
    "\n",
    "# GET NODES NAMES\n",
    "list_name_nodes = []\n",
    "name_nodes_conn = conn.getVertices(\"Nodes\")\n",
    "for i in range(0, len(name_nodes_conn)):\n",
    "    list_name_nodes.append(name_nodes_conn[i][\"v_id\"])\n",
    "\n",
    "def add_edge(source_vertex_id, target_vertex_id, attributes_dict=None, vertex_type=\"Nodes\", edgeType=\"distribute_to\"):\n",
    "    if attributes_dict is None:\n",
    "        conn.upsertEdge(sourceVertexType=vertex_type,\n",
    "                        targetVertexType=vertex_type,\n",
    "                        edgeType=edgeType,\n",
    "                        sourceVertexId=source_vertex_id,\n",
    "                        targetVertexId=target_vertex_id)\n",
    "        message =  f\"Edge from {source_vertex_id} to {target_vertex_id} added\"\n",
    "        logs_modif_network +=message\n",
    "        return logs_modif_network\n",
    "    else:\n",
    "        attributes = json.loads(attributes_dict)\n",
    "        conn.upsertEdge(sourceVertexType=vertex_type,\n",
    "                        targetVertexType=vertex_type,\n",
    "                        edgeType=edgeType,\n",
    "                        sourceVertexId=source_vertex_id,\n",
    "                        targetVertexId=target_vertex_id,\n",
    "                        attributes=attributes)\n",
    "        message =  f\"Edge from {source_vertex_id} to {target_vertex_id} added with attributes {attributes}\"\n",
    "        logs_modif_network +=message\n",
    "        return logs_modif_network\n",
    "\n",
    "\n",
    "def erase_edge(source_vertex_id, target_vertex_id, vertex_type = \"Nodes\", edgeType = \"distribute_to\"):\n",
    "    conn.delEdges(sourceVertexType=vertex_type,\n",
    "                    targetVertexType=vertex_type,\n",
    "                    edgeType=edgeType,\n",
    "                    sourceVertexId=source_vertex_id,\n",
    "                    targetVertexId=target_vertex_id)\n",
    "    message =  f\"Edge  from {source_vertex_id} to {target_vertex_id} deleted \\n\"\n",
    "    logs_modif_network +=message\n",
    "    return logs_modif_network\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def erase_node(id ,vertex_type = \"Nodes\"):\n",
    "    conn.delVerticesById(vertexIds=id,vertexType=vertex_type)\n",
    "    message =  f\"Node {id} deleted\"\n",
    "    logs_modif_network +=message\n",
    "    return logs_modif_network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Tab 3 (algorithms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def launch_instaled_algo(algorithm,params_str):\n",
    "    params = json.loads(params_str)\n",
    "    results = conn.runInstalledQuery(algorithm, params= params)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "VertexTypes = conn.getVertexTypes()\n",
    "EdgeTypes = conn.getEdgeTypes()\n",
    "EdgeAtributes = conn.getEdgeAttrs(\"distribute_to\")[0][0]\n",
    "data_algo = conn.getInstalledQueries(fmt=\"py\")\n",
    "installed_algorithms = [key.split(\"/\")[-1] for key in data_algo.keys() if key.startswith(\"GET /query/VWG/\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tab 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "def networkx_maxflow(data):\n",
    "    data = eval(data)\n",
    "    max_flow = data[0]['@@sum_max_flow']\n",
    "    edge_set = data[1]['@@edges_set']\n",
    "\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    # Add edges with capacities\n",
    "    for edge in edge_set:\n",
    "        from_node = edge['from_id']\n",
    "        to_node = edge['to_id']\n",
    "        capacity = edge['attributes']['Capacity']\n",
    "        G.add_edge(from_node, to_node, capacity=capacity)\n",
    "\n",
    "    pos = nx.spring_layout(G)\n",
    "    nx.draw(G, pos, with_labels=True, node_size=700, node_color='lightblue', font_size=10, font_weight='bold')  # Draw nodes\n",
    "    nx.draw_networkx_edge_labels(G, pos, edge_labels={(u, v): f\"{d['capacity']}\" for u, v, d in G.edges(data=True)}, font_color='red')  # Edge labels\n",
    "    plt.title(f\"Max Flow: {max_flow}\")\n",
    "    plt.show()\n",
    "\n",
    "    buf = BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    buf.seek(0)\n",
    "    img = Image.open(buf)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "def networkx_astar(data):\n",
    "    data = eval(data)\n",
    "    node_data = {item['v_id']: item['attributes'] for item in data[2]['tmp']}\n",
    "    edge_data = [{'from': edge['from_id'], 'to': edge['to_id'], 'capacity': edge['attributes']['Capacity']} for edge in data[2]['@@display_edge_set']]\n",
    "\n",
    "    G = nx.Graph()\n",
    "\n",
    "    # Add nodes\n",
    "    for node_id, attributes in node_data.items():\n",
    "        G.add_node(node_id, **attributes)\n",
    "\n",
    "    # Add edges\n",
    "    for edge in edge_data:\n",
    "        G.add_edge(edge['from'], edge['to'], capacity=edge['capacity'])\n",
    "\n",
    "    pos = nx.spring_layout(G)  # Nodes\n",
    "    nx.draw(G, pos, with_labels=True, node_size=700, node_color='lightblue', font_size=10, font_weight='bold')  # Draw Edges\n",
    "    nx.draw_networkx_edge_labels(G, pos, edge_labels={(edge['from'], edge['to']): f\"{edge['capacity']}\" for edge in edge_data}, font_color='red')  # Edge label\n",
    "    plt.title(\"Graphe avec NetworkX\")\n",
    "    plt.show()\n",
    "    from io import BytesIO\n",
    "    from PIL import Image\n",
    "    buf = BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    buf.seek(0)\n",
    "    img = Image.open(buf)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_path(input_file):\n",
    "    df = pd.read_csv(input_file.name)\n",
    "    target_column = sorted(list(df.columns))\n",
    "    return  gr.Dropdown(choices = target_column) , gr.Dropdown(choices = target_column) , gr.Dropdown(choices = target_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'read_csv_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 133\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    131\u001b[0m     lis \u001b[38;5;241m=\u001b[39m GradioMetro()\n\u001b[1;32m--> 133\u001b[0m     \u001b[43mlis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfront_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 20\u001b[0m, in \u001b[0;36mGradioMetro.front_func\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     18\u001b[0m dropdown_column_quantity \u001b[38;5;241m=\u001b[39m gr\u001b[38;5;241m.\u001b[39mDropdown(label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mColumna de la cantidad\u001b[39m\u001b[38;5;124m'\u001b[39m, choices \u001b[38;5;241m=\u001b[39m [],  interactive\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_custom_value\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, elem_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropdown\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     19\u001b[0m load_data_send \u001b[38;5;241m=\u001b[39m gr\u001b[38;5;241m.\u001b[39mButton(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLanzar los envios\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m upload_file\u001b[38;5;241m.\u001b[39mupload(\u001b[43mread_csv_path\u001b[49m,inputs\u001b[38;5;241m=\u001b[39m[upload_file],outputs\u001b[38;5;241m=\u001b[39m[dropdown_column_start,dropdown_column_arrival,dropdown_column_quantity])\n\u001b[0;32m     21\u001b[0m logs \u001b[38;5;241m=\u001b[39m gr\u001b[38;5;241m.\u001b[39mTextArea(label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLogs\u001b[39m\u001b[38;5;124m\"\u001b[39m,lines\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m     22\u001b[0m load_data_send\u001b[38;5;241m.\u001b[39mclick(make_daily_movements,inputs\u001b[38;5;241m=\u001b[39m[upload_file,dropdown_column_start,dropdown_column_arrival,dropdown_column_quantity], outputs\u001b[38;5;241m=\u001b[39m[logs])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'read_csv_path' is not defined"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 4.27.0, however version 4.29.0 is available, please upgrade.\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "atributes_nodes = {}\n",
    "atributes_edges = {}\n",
    "\n",
    "class GradioMetro:\n",
    "    \n",
    "    def front_func(self):\n",
    "        with gr.Blocks(css=\"Gradio/styles.css\", title =\"Graphs\") as demo:\n",
    "            gr.Markdown(\"## \"\"![](file/Gradio/logo_lis.svg) Graphs\"\"\", elem_classes=\"cabecero\")\n",
    "            with gr.Tabs() as tabs:\n",
    "                with gr.TabItem(\"Cargar movimientos\",id=0):\n",
    "                    with gr.Row():\n",
    "                        with gr.Column(scale=1):\n",
    "                            upload_file = gr.File(label=\"Cargar fichero\", type=\"filepath\")\n",
    "                        with gr.Column():\n",
    "                            dropdown_column_start = gr.Dropdown(label='Columna del envio', choices = [],  interactive=True, allow_custom_value= True, elem_classes=\"dropdown\")\n",
    "                            dropdown_column_arrival = gr.Dropdown(label='Columna de la llegada', choices = [],  interactive=True, allow_custom_value= True, elem_classes=\"dropdown\")\n",
    "                            dropdown_column_quantity = gr.Dropdown(label='Columna de la cantidad', choices = [],  interactive=True, allow_custom_value= True, elem_classes=\"dropdown\")\n",
    "                            load_data_send = gr.Button(\"Lanzar los envios\")\n",
    "                            upload_file.upload(read_csv_path,inputs=[upload_file],outputs=[dropdown_column_start,dropdown_column_arrival,dropdown_column_quantity])\n",
    "                            logs = gr.TextArea(label=\"Logs\",lines=10)\n",
    "                            load_data_send.click(make_daily_movements,inputs=[upload_file,dropdown_column_start,dropdown_column_arrival,dropdown_column_quantity], outputs=[logs])\n",
    "                \n",
    "                \n",
    "                with gr.TabItem(\"KPIs movimiento\",id=1):\n",
    "                    with gr.Row():\n",
    "                        with gr.Column(scale=10):\n",
    "                            gr.HTML(value = \"\"\" <html lang=\"en\"><head><meta charset=\"UTF-8\"><meta name=\"viewport\" content=\"width=device-width, \n",
    "                                    initial-scale=1.0\"></head><body><iframe width=\"800\" height=\"800\"\n",
    "                                    src=\"\"\" + tigergraph_insights_map + \"\"\" \n",
    "                                    title=\"tigergarph insights\" frameborder=\"0\"></iframe></body></html>\"\"\")   \n",
    "                        with gr.Column():\n",
    "                            operation_number = gr.Number(label= \"KPI : Numero de operaciones\")\n",
    "                            palets_number = gr.Number(label= \"KPI : Numero de palets\")\n",
    "                            origin_number = gr.Number(label= \"KPI : Numero de origen\")\n",
    "                            distinct_destinations = gr.Number(label= \"KPI : destinaciones diferentes\")\n",
    "                            total_cost = gr.Number(label= \"KPI : Coste total\")\n",
    "                            total_cost_per_palet = gr.Number(label= \"KPI : Coste por palet\")\n",
    "                            button = gr.Button(\"Calcular KPIs\")\n",
    "                            button.click(get_KPIs_movements , outputs= [operation_number,palets_number,origin_number,distinct_destinations,total_cost,total_cost_per_palet]) \n",
    "\n",
    "\n",
    "                with gr.TabItem(\"KPIs red\",id=2):\n",
    "                    with gr.Row():\n",
    "                        with gr.Column(scale=10):\n",
    "                            gr.HTML(value = \"\"\" <html lang=\"en\"><head><meta charset=\"UTF-8\"><meta name=\"viewport\" content=\"width=device-width, \n",
    "                                    initial-scale=1.0\"></head><body><iframe width=\"800\" height=\"800\"\n",
    "                                    src=\"\"\" + tigergraph_insights_map + \"\"\" \n",
    "                                    title=\"tigergarph insights\" frameborder=\"0\"></iframe></body></html>\"\"\")   \n",
    "                        with gr.Column():\n",
    "                            Numedges = gr.Number(label=\"KPI : Cantidad de Aristas\")\n",
    "                            Numnodes = gr.Number(label=\"KPI : Cantidad de Nodos\")\n",
    "                            average_cost_per_edge = gr.Number(label= \"KPI : Coste medio / Arista\")\n",
    "                            capacidad_total_aristas = gr.Number(label=\"KPI : Capacidad total de las aristas \")\n",
    "                            warehouse_total_capacity = gr.Number(label= \"KPI : Capacidad total de los Almacenes\")\n",
    "                            warehouse_total_stock = gr.Number(label=\"KPI : Stock total de los almacenes\")\n",
    "                            button = gr.Button(\"Calcular KPIs\")\n",
    "                            button.click(get_KPIs_network , outputs= [Numedges,Numnodes,average_cost_per_edge,capacidad_total_aristas,warehouse_total_capacity,warehouse_total_stock]) \n",
    "                \n",
    "                with gr.TabItem(\"add nodes\", id=3):\n",
    "                    new_node_id = gr.Textbox(label=\"Node ID\")\n",
    "                    for e in attributes_nodes_list:\n",
    "                        with gr.Row():\n",
    "                            atributes_nodes[e] = gr.Number(label=e)\n",
    "                \n",
    "                    with gr.Row():\n",
    "                        btn = gr.Button(\"Add Node\")\n",
    "                        output = gr.Textbox()\n",
    "\n",
    "                    inputs = [new_node_id] + [atributes_nodes[e] for e in attributes_nodes_list]\n",
    "                    btn.click(fn=add_node_with_values, inputs=inputs, outputs=output)\n",
    "\n",
    "\n",
    "                with gr.TabItem(\"add edges\", id=4):\n",
    "                    source_vertex_id = gr.Textbox(label=\"Source Vertex ID\")\n",
    "                    target_vertex_id = gr.Textbox(label=\"Target Vertex ID\")\n",
    "\n",
    "                    for e in attributes_edges_list:\n",
    "                        with gr.Row():\n",
    "                            atributes_edges[e] = gr.Number(label=e)\n",
    "\n",
    "                    with gr.Row():\n",
    "                        btn = gr.Button(\"Add Edge\")\n",
    "                        output = gr.Textbox()\n",
    "\n",
    "                        inputs = [\n",
    "                            source_vertex_id,\n",
    "                            target_vertex_id\n",
    "                        ] + [atributes_edges[e] for e in attributes_edges_list]\n",
    "                        btn.click(fn=add_edge_with_values, inputs=inputs, outputs=output)\n",
    "\n",
    "                with gr.TabItem(\"Modificación red-arrista\",id=5):\n",
    "                    with gr.Row():\n",
    "\n",
    "                        with gr.Column():   #ERASE \n",
    "                            source_node_id = gr.Dropdown(list_name_nodes,label='Punto de origen')\n",
    "                            target_node_id = gr.Dropdown(list_name_nodes,label='Punto de destinacion')\n",
    "\n",
    "                        with gr.Column():   #ADD\n",
    "                            attributes_edges_list_gradio = gr.Dropdown(attributes_edges_list,label='Atributos aristas')\n",
    "                            atributes_dict = gr.Number(label='Valor')\n",
    "                            button_add_edge = gr.Button(\"Añadir/modificar arista\")\n",
    "                            button_add_edge.click(add_new_edge ,inputs = [source_node_id,target_node_id,atributes_dict]) \n",
    "\n",
    "                            button_erase_edge = gr.Button(\"Borrar arista\")\n",
    "\n",
    "                        with gr.Column():\n",
    "                            logs = gr.TextArea(label=\"Logs\",lines=10)\n",
    "                            button_erase_edge.click(erase_edge, inputs = [source_node_id,target_node_id])\n",
    "                            \n",
    "                with gr.TabItem(\"KPIs movimiento alternativo\",id=6):\n",
    "                    with gr.Row():\n",
    "                        with gr.Column(scale=10):\n",
    "                            gr.HTML(value = \"\"\" <html lang=\"en\"><head><meta charset=\"UTF-8\"><meta name=\"viewport\" content=\"width=device-width, \n",
    "                                    initial-scale=1.0\"></head><body><iframe width=\"800\" height=\"800\"\n",
    "                                    src=\"\"\" + tigergraph_insights_map + \"\"\" \n",
    "                                    title=\"tigergarph insights\" frameborder=\"0\"></iframe></body></html>\"\"\")   \n",
    "                        with gr.Column():\n",
    "                            path_1 = gr.TextArea(label=\"Camino alternativo 1\",lines=3)\n",
    "                            path_2 = gr.TextArea(label=\"Camino alternativo 2\",lines=3)\n",
    "                            price_1 = gr.TextArea(label=\"KPI : Precio camino alternativo 1\")\n",
    "                            price_2 = gr.TextArea(label=\"KPI : Precio camino alternativo 2\") \n",
    "                            button = gr.Button(\"Calcular KPIs\")\n",
    "                            button.click(get_KPIs_alternatives , outputs= [path_1,price_1,path_2,price_2]) \n",
    "\n",
    "\n",
    "                demo.launch(max_threads=1000)\n",
    "                \n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    lis = GradioMetro()\n",
    "    \n",
    "    lis.front_func()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
